{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d65a6a-c6be-4af4-bc2a-ed1398746712",
   "metadata": {},
   "source": [
    "### Ingests a single set of ADC, HDR and Class files \n",
    "\n",
    "Takes the required info from each file and creates single merged file \n",
    "Logic\n",
    "1) Parse ADCFileFormat from .hdr to get column names\n",
    "2) Load .adc with those headers\n",
    "3) Add RoiNumber to ADC as 1 - N\n",
    "4) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 -- this removes zero roi triggers so we can merge with class file on roi number\n",
    "5) Add InhibitTimeDiff = diff(InhibitTime).fillna(0) -- useful for understanding sample density\n",
    "6) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240  -- needed for concentration estimates and also useful for understanding sample density\n",
    "7) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23) -- used to merge with adc file\n",
    "8) Merge class_df with ADC-derived columns on RoiNumber\n",
    "9) Return merged_df (and adc_df, class_df)\n",
    "\n",
    "This gives you dataset of all rois with class scores and associated ADC metadata\n",
    "\n",
    "#### NOTE: Has been updated use the second version that is below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65a3ec-f4f3-4cb8-a6f7-7cc34d035d41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Version 1 Dont use this !\n",
    "saved for future incase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2145f1b4-301d-4bb1-a7e3-88bd86c4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: str,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Parse ADCFileFormat from .hdr to get column names\n",
    "      2) Load .adc with those headers\n",
    "      3) Add RoiNumber to ADC as 1..N\n",
    "      4) (NEW) Drop false trigger if present: RunTime < 0.25 AND zero ROI\n",
    "      5) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 (optionally)\n",
    "      6) Add InhibitTimeDiff with special first-row rule\n",
    "      7) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240\n",
    "      8) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23)\n",
    "      9) Merge class_df with ADC-derived columns on RoiNumber\n",
    "      10) Return merged_df (and adc_df, class_df)\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path)\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(\"ADCFileFormat not found in header file.\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger if present (before any other filtering) ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            # Drop it if present; keep original RoiNumber values; don't reset index\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (first real trigger uses cumulative inhibit time)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # First remaining row (first real trigger): InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # Safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # 7) Load class CSV + extract RoiNumber from pid\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    if 'pid' not in class_df.columns:\n",
    "        raise ValueError(\"Expected 'pid' column in class CSV to extract RoiNumber.\")\n",
    "    class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # 8) Merge on RoiNumber\n",
    "    cols_to_keep = ['RoiNumber', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    merged_df = class_df.merge(adc_df[cols_to_keep], on='RoiNumber', how='left')\n",
    "\n",
    "    # 9) Return\n",
    "    return merged_df, adc_df, class_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cec2d-252f-4a06-bbe4-9f8bfeeb1c68",
   "metadata": {},
   "source": [
    "## Loops over a directory and outputs a merged directory\n",
    "\n",
    "wrapper for the ingest_ifcb function that merges based on the initial string of the file names and writes out merged datasets to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08e1e6a4-5051-4f72-9927-bc3ebb4a6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "import fnmatch\n",
    "\n",
    "def ingest_ifcb_directory(directory: str,\n",
    "                          drop_zero_roi: bool = True,\n",
    "                          save_path: str | None = None,\n",
    "                          # ---- NEW (optional) ----\n",
    "                          drop_false_trigger: bool = True,\n",
    "                          false_trigger_runtime_s: float = 0.25,\n",
    "                          class_suffixes: Optional[tuple] = None,\n",
    "                          prefer_newest_class_file: bool = True\n",
    "                          ) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loop over a directory, find sets of .adc, .hdr, and class CSV files\n",
    "    that share the same IFCB run prefix, and return merged dataframes.\n",
    "\n",
    "    Minimal changes:\n",
    "      - class file detection is now prefix-based and flexible (handles variable suffixes)\n",
    "      - passes drop_false_trigger + false_trigger_runtime_s into ingest_ifcb\n",
    "\n",
    "    Args:\n",
    "        directory: Folder containing IFCB .adc, .hdr, and class CSV files.\n",
    "        drop_zero_roi: Passed to ingest_ifcb().\n",
    "        save_path: Optional folder to save merged CSVs.\n",
    "        drop_false_trigger: If True, drop early false trigger(s) in ingest_ifcb.\n",
    "        false_trigger_runtime_s: Runtime cutoff for false trigger rule.\n",
    "        class_suffixes: Optional patterns/suffixes for class files.\n",
    "            - If None (default): accept any CSV that starts with prefix and contains 'class'\n",
    "            - If provided: may include exact suffixes or wildcard patterns, e.g. (\"_class*.csv\",)\n",
    "        prefer_newest_class_file: If multiple class files match, choose newest (True) or name-sorted (False).\n",
    "\n",
    "    Returns:\n",
    "        dict: { prefix : merged_dataframe }\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_files = list(directory.glob(\"*.adc\"))\n",
    "    hdr_files = list(directory.glob(\"*.hdr\"))\n",
    "    class_files = list(directory.glob(\"*class*.csv\"))\n",
    "\n",
    "    # Build file lookup maps\n",
    "    adc_map = {f.stem: f for f in adc_files}\n",
    "    hdr_map = {f.stem: f for f in hdr_files}\n",
    "\n",
    "    # Only consider prefixes that have adc+hdr (required)\n",
    "    prefixes = sorted(set(adc_map.keys()).intersection(set(hdr_map.keys())))\n",
    "\n",
    "    def _class_matches(prefix: str, filename: str) -> bool:\n",
    "        # Must start with the prefix (strong constraint)\n",
    "        if not filename.startswith(prefix):\n",
    "            return False\n",
    "\n",
    "        # If no suffix patterns provided, accept any \"class\" csv starting with prefix\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        # Otherwise allow exact suffixes OR wildcard patterns\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                # interpret token as a suffix pattern, e.g. \"_class*.csv\"\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                # interpret token as exact suffix\n",
    "                if filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class map by searching best match per prefix\n",
    "    class_map = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = [f for f in class_files if _class_matches(prefix, f.name)]\n",
    "        if matches:\n",
    "            best = max(matches, key=lambda x: x.stat().st_mtime) if prefer_newest_class_file else sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    merged_results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map.get(prefix)\n",
    "        hdr_path = hdr_map.get(prefix)\n",
    "        class_path = class_map.get(prefix)\n",
    "\n",
    "        # Require class file too (matches your original behavior)\n",
    "        if not class_path:\n",
    "            print(f\"Skipping {prefix}: missing class CSV.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        merged_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path),\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            # ---- pass-through new logic ----\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s\n",
    "        )\n",
    "\n",
    "        merged_results[prefix] = merged_df\n",
    "\n",
    "        # Save output to designated location\n",
    "        outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        merged_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved merged file â†’ {outfile}\")\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59245ed6-33e8-4e76-ab1f-556d1e8bfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac68709-f90c-4e6a-849f-9d5756356e6f",
   "metadata": {},
   "source": [
    "### Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "942fa757-72b7-4da7-aad0-a9467d78e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/AlexandriumTest/\"\n",
    "merged_dir = \"../../IFCBData/AlexandriumTest/newmerged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "061e8152-ae41-4838-8fb0-ab83dcbe3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240501T200201_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429804-cf96-4e37-9896-4b4f702fa89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1436e46e-5127-488a-b2fe-0ff0bb763dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38c7e0db-e7c0-49d4-9a66-ce3b8f534a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0             2     4.931790     4.953893     0.083047         0.000000   \n",
      "1             3     5.104920     5.127059     0.166803         0.083757   \n",
      "2             4     5.774158     5.796293     0.249392         0.082589   \n",
      "3             5     5.865553     5.888199     0.333301         0.083908   \n",
      "4             6     5.952413     5.972958     0.414779         0.081478   \n",
      "...         ...          ...          ...          ...              ...   \n",
      "6378       6786  1198.809496  1198.831528   517.552604         0.083160   \n",
      "6379       6787  1199.135671  1199.157500   517.634792         0.082187   \n",
      "6380       6789  1199.493438  1199.514583   517.801215         0.166424   \n",
      "6381       6790  1200.150306  1200.174167   517.885764         0.084549   \n",
      "6382       6791  1200.525941  1200.548333   517.968507         0.082743   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0           0.020295         44        88   948   534  \n",
      "1           0.020668        188       208   764   630  \n",
      "2           0.023112         84       104   892   782  \n",
      "3           0.023145        204       248   740   342  \n",
      "4           0.023159        204       240   748   398  \n",
      "...              ...        ...       ...   ...   ...  \n",
      "6378        2.838662         60        96   900   782  \n",
      "6379        2.839678         68        96   876   782  \n",
      "6380        2.840472         44        64   932   758  \n",
      "6381        2.842868         68       120   884   838  \n",
      "6382        2.844083         68       144   884   630  \n",
      "\n",
      "[6383 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87504f37-49ba-43cf-8cef-1760e1d0918d",
   "metadata": {},
   "source": [
    "# Version2\n",
    "\n",
    "## USE THIS VERSION: Class file optional Versions -- same logic just now can handle missing class files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac70280-fc63-41ed-bbe3-f6f839803bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bee5b-fdf2-4796-b979-fda52b04872b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bfa228bb-ca2f-443f-8744-82dd1680f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: Optional[str] = None,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25\n",
    "                ) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    NEW:\n",
    "      - drops early false trigger(s) if: RunTime < false_trigger_runtime_s AND (RoiX=RoiY=RoiHeight=RoiWidth=0)\n",
    "      - recomputes InhibitTimeDiff after dropping false triggers:\n",
    "            first row: InhibitTimeDiff = InhibitTime\n",
    "            later rows: InhibitTimeDiff = diff(InhibitTime)\n",
    "\n",
    "    Returns:\n",
    "        merged_df:\n",
    "            - if class provided & exists: class_df merged with adc-derived columns on RoiNumber\n",
    "            - else: adc-derived dataframe containing RoiNumber + derived columns (and ROI geometry if present)\n",
    "        adc_df: ADC dataframe with parsed headers + derived columns\n",
    "        class_df: class dataframe if loaded, else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger(s) BEFORE drop_zero_roi ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            # numeric coercion for robust comparisons\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]  # preserve RoiNumber, don't reset index\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (with special first-row rule after filtering)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # first remaining row: InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0.0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber', 'ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        merged_df = class_df.merge(adc_out, on='RoiNumber', how='left')\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "24f0bbb1-7d9b-420f-b04b-a737d201cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    "    # ---- NEW (optional) ----\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process a folder of IFCB files. For each prefix:\n",
    "      - requires .adc and .hdr\n",
    "      - class CSV is optional\n",
    "\n",
    "    Class CSV matching (more flexible):\n",
    "      - We derive prefixes from .adc/.hdr stems\n",
    "      - For each prefix, we look for CSVs that:\n",
    "          1) start with that prefix\n",
    "          2) contain 'class' (case-insensitive)\n",
    "          3) AND (if class_suffixes provided) match ANY of the provided patterns/suffixes\n",
    "\n",
    "    NEW:\n",
    "      - Passes drop_false_trigger + false_trigger_runtime_s to ingest_ifcb\n",
    "\n",
    "    Writes outputs to save_path (or the input directory if None).\n",
    "\n",
    "    Returns:\n",
    "      dict {prefix: output_df}\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    # Only process prefixes that actually have adc+hdr\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    # Candidate class CSVs: anything with 'class' in the filename\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        \"\"\"\n",
    "        Match logic:\n",
    "          - If class_suffixes is None/empty: accept any class candidate starting with prefix.\n",
    "          - Else: for each token in class_suffixes:\n",
    "              * If token has wildcards -> use fnmatch against:\n",
    "                    - f\"{prefix}{token}\"  (token interpreted as suffix/pattern)\n",
    "                    - token itself (in case user passes full pattern)\n",
    "              * If token has no wildcards -> treat as suffix and require filename.endswith(token)\n",
    "        \"\"\"\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class_map keyed by prefix\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "        class_path = class_map.get(prefix)  # may be None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            # ---- NEW: pass-through ----\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s,\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # Save with different suffix depending on whether class exists\n",
    "        if class_df is not None:\n",
    "            outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac463b8-b1c6-42af-b927-1beea9b886cd",
   "metadata": {},
   "source": [
    "## Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51889411-2e8c-4bdf-a96b-7d8dc2a85a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/AlexandriumTest/\"\n",
    "merged_dir = \"../../IFCBData/AlexandriumTest/newmerged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f264f715-d296-4d0e-9847-8f5277551222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240420T095637_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/newmerged/D20240420T095637_IFCB124_merged.csv\n",
      "Processing D20240423T013135_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/newmerged/D20240423T013135_IFCB124_merged.csv\n",
      "Processing D20240429T195718_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/newmerged/D20240429T195718_IFCB124_merged.csv\n",
      "Processing D20240429T213320_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/newmerged/D20240429T213320_IFCB124_merged.csv\n",
      "Processing D20240501T235832_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/newmerged/D20240501T235832_IFCB124_merged.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                    #class_suffixes=\"_class_scores.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98704bfe-f0e5-49c2-ab53-5d03b237ab07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a05f7de8-f6ec-4b48-8f2c-09d70db26b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/AlexandriumTest/newmerged/D20240420T095637_IFCB124_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4bcf4236-3228-41bd-a154-cd8b0353c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               pid  Alexandrium_catenella  \\\n",
      "0   D20240420T095637_IFCB124_00002           0.000000e+00   \n",
      "1   D20240420T095637_IFCB124_00003           0.000000e+00   \n",
      "2   D20240420T095637_IFCB124_00004           8.030000e-01   \n",
      "3   D20240420T095637_IFCB124_00005           7.150000e-06   \n",
      "4   D20240420T095637_IFCB124_00006           9.214000e-01   \n",
      "5   D20240420T095637_IFCB124_00007           9.946000e-01   \n",
      "6   D20240420T095637_IFCB124_00008           9.995000e-01   \n",
      "7   D20240420T095637_IFCB124_00009           9.995000e-01   \n",
      "8   D20240420T095637_IFCB124_00010           2.400000e-07   \n",
      "9   D20240420T095637_IFCB124_00011           3.198000e-01   \n",
      "10  D20240420T095637_IFCB124_00012           9.976000e-01   \n",
      "11  D20240420T095637_IFCB124_00013           0.000000e+00   \n",
      "12  D20240420T095637_IFCB124_00014           7.180000e-01   \n",
      "13  D20240420T095637_IFCB124_00015           1.816000e-02   \n",
      "14  D20240420T095637_IFCB124_00016           9.434000e-01   \n",
      "15  D20240420T095637_IFCB124_00017           6.000000e-08   \n",
      "16  D20240420T095637_IFCB124_00018           5.645000e-01   \n",
      "17  D20240420T095637_IFCB124_00019           2.000000e-07   \n",
      "18  D20240420T095637_IFCB124_00020           8.163000e-04   \n",
      "19  D20240420T095637_IFCB124_00021           3.640000e-01   \n",
      "\n",
      "    Alexandrium_catenella_TAG_2cell_TAG_chain  \\\n",
      "0                                0.000000e+00   \n",
      "1                                3.900000e-06   \n",
      "2                                1.106000e-02   \n",
      "3                                2.205000e-05   \n",
      "4                                3.223000e-03   \n",
      "5                                2.430000e-03   \n",
      "6                                9.406000e-05   \n",
      "7                                9.406000e-05   \n",
      "8                                1.130000e-06   \n",
      "9                                5.370000e-02   \n",
      "10                               1.275000e-03   \n",
      "11                               0.000000e+00   \n",
      "12                               4.962000e-02   \n",
      "13                               3.195000e-02   \n",
      "14                               4.230000e-03   \n",
      "15                               7.000000e-07   \n",
      "16                               4.930000e-02   \n",
      "17                               9.500000e-07   \n",
      "18                               1.399000e-03   \n",
      "19                               4.890000e-03   \n",
      "\n",
      "    Alexandrium_catenella_TAG_4cell_TAG_chain  \\\n",
      "0                                0.000000e+00   \n",
      "1                                0.000000e+00   \n",
      "2                                0.000000e+00   \n",
      "3                                0.000000e+00   \n",
      "4                                0.000000e+00   \n",
      "5                                0.000000e+00   \n",
      "6                                0.000000e+00   \n",
      "7                                0.000000e+00   \n",
      "8                                0.000000e+00   \n",
      "9                                2.000000e-07   \n",
      "10                               0.000000e+00   \n",
      "11                               0.000000e+00   \n",
      "12                               6.000000e-08   \n",
      "13                               8.600000e-06   \n",
      "14                               0.000000e+00   \n",
      "15                               0.000000e+00   \n",
      "16                               0.000000e+00   \n",
      "17                               0.000000e+00   \n",
      "18                               0.000000e+00   \n",
      "19                               0.000000e+00   \n",
      "\n",
      "    Alexandrium_catenella_TAG_dividing  Alexandrium_catenella_TAG_fusing  \\\n",
      "0                         0.000000e+00                      0.000000e+00   \n",
      "1                         6.000000e-08                      6.000000e-08   \n",
      "2                         3.262000e-04                      5.140000e-03   \n",
      "3                         1.810000e-05                      3.950000e-05   \n",
      "4                         1.291000e-04                      1.739500e-03   \n",
      "5                         2.195000e-04                      8.974000e-04   \n",
      "6                         6.000000e-08                      4.050000e-06   \n",
      "7                         6.000000e-08                      1.600000e-05   \n",
      "8                         2.000000e-07                      4.000000e-07   \n",
      "9                         2.304000e-03                      3.733000e-01   \n",
      "10                        3.280000e-05                      6.530000e-04   \n",
      "11                        0.000000e+00                      0.000000e+00   \n",
      "12                        9.000000e-05                      3.766000e-02   \n",
      "13                        1.284000e-02                      1.614000e-02   \n",
      "14                        1.960000e-05                      3.675000e-03   \n",
      "15                        1.000000e-07                      3.600000e-07   \n",
      "16                        2.294000e-04                      2.740000e-03   \n",
      "17                        0.000000e+00                      6.000000e-08   \n",
      "18                        9.300000e-04                      6.332000e-04   \n",
      "19                        6.935000e-03                      4.041000e-04   \n",
      "\n",
      "          Amoeba        Amylax    Apedinella  Asterionellopsis_glacialis  ...  \\\n",
      "0   0.000000e+00  0.000000e+00  0.000000e+00                0.000000e+00  ...   \n",
      "1   1.628000e-03  0.000000e+00  0.000000e+00                1.260000e-05  ...   \n",
      "2   3.690000e-05  3.520000e-05  1.670000e-06                3.160000e-06  ...   \n",
      "3   2.956000e-05  1.391000e-04  0.000000e+00                8.300000e-07  ...   \n",
      "4   1.200000e-06  1.460000e-05  6.440000e-06                2.440000e-06  ...   \n",
      "5   2.000000e-07  1.597000e-04  1.000000e-07                2.000000e-07  ...   \n",
      "6   0.000000e+00  6.000000e-08  0.000000e+00                0.000000e+00  ...   \n",
      "7   3.000000e-07  0.000000e+00  0.000000e+00                0.000000e+00  ...   \n",
      "8   2.000000e-07  0.000000e+00  0.000000e+00                1.850000e-06  ...   \n",
      "9   1.525000e-03  6.123000e-04  4.153000e-04                9.240000e-06  ...   \n",
      "10  6.000000e-08  9.000000e-07  3.600000e-07                5.400000e-07  ...   \n",
      "11  5.100000e-06  0.000000e+00  0.000000e+00                1.130000e-06  ...   \n",
      "12  8.583000e-04  2.407000e-03  9.050000e-05                2.563000e-05  ...   \n",
      "13  2.337000e-05  2.697000e-03  2.042000e-04                1.404000e-03  ...   \n",
      "14  3.138000e-04  6.400000e-06  4.500000e-06                1.407000e-05  ...   \n",
      "15  8.300000e-07  0.000000e+00  0.000000e+00                1.850000e-06  ...   \n",
      "16  2.400000e-06  3.166000e-03  2.740000e-06                9.000000e-04  ...   \n",
      "17  6.310000e-05  0.000000e+00  1.000000e-06                3.020000e-05  ...   \n",
      "18  9.000000e-07  2.571000e-03  0.000000e+00                2.150000e-06  ...   \n",
      "19  6.000000e-08  1.070000e-03  1.000000e-07                1.250000e-06  ...   \n",
      "\n",
      "    RoiNumber    ADCtime    RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0           2   7.975714   8.002049     0.075228         0.075228   \n",
      "1           3   8.841708   8.862817     0.905243         0.830015   \n",
      "2           4   8.882137   8.931997     0.970729         0.065486   \n",
      "3           5   8.951330   9.007261     1.038776         0.068047   \n",
      "4           6   9.027408   9.075471     1.088641         0.049865   \n",
      "5           7   9.095817   9.146539     1.157244         0.068602   \n",
      "6           8   9.166524   9.210718     1.206914         0.049670   \n",
      "7           9   9.231235   9.273181     1.257194         0.050280   \n",
      "8          10   9.293368   9.355790     1.304538         0.047344   \n",
      "9          11   9.369797   9.452704     1.345699         0.041161   \n",
      "10         12   9.466709   9.523830     1.386886         0.041187   \n",
      "11         13   9.537818   9.559659     1.391343         0.004457   \n",
      "12         14   9.712853   9.734021     1.461443         0.070100   \n",
      "13         15   9.800265   9.822823     1.542567         0.081124   \n",
      "14         16   9.908769   9.931057     1.624549         0.081981   \n",
      "15         17  10.100039  10.122847     1.706992         0.082444   \n",
      "16         18  10.199344  10.221539     1.788843         0.081851   \n",
      "17         19  10.320387  10.342539     1.870725         0.081882   \n",
      "18         20  10.420935  10.443171     1.952617         0.081892   \n",
      "19         21  10.554032  10.576886     2.034883         0.082266   \n",
      "\n",
      "    VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0         0.033028         44        80   836   598  \n",
      "1         0.033157         52        88   860   470  \n",
      "2         0.033172        132       160   788   390  \n",
      "3         0.033202        132       152   780   662  \n",
      "4         0.033278        124       152   788   214  \n",
      "5         0.033289        140       152   796   462  \n",
      "6         0.033349        132       176   756   726  \n",
      "7         0.033400        124       160   764   726  \n",
      "8         0.033547         44        64   876   454  \n",
      "9         0.033779        108       160   796   366  \n",
      "10        0.033904        124       176   764   702  \n",
      "11        0.034035         60       112   836   526  \n",
      "12        0.034469        132       152   796   246  \n",
      "13        0.034501        116       136   804   310  \n",
      "14        0.034610        108       136   812   350  \n",
      "15        0.035066         44        72   876   358  \n",
      "16        0.035136        132       192   740   550  \n",
      "17        0.035299         60        88   860   350  \n",
      "18        0.035377        140       152   780   710  \n",
      "19        0.035592        140       160   780   502  \n",
      "\n",
      "[20 rows x 147 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27d467-606f-46f2-9d9d-6d6a518fc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c546318-b6b5-441b-8e41-1df2ec01827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroroi_out_df, zeroroi_adc_df, testy_df = ingest_ifcb(adc_path= \"../../IFCBData/DenseAlex/nauset/D20240402T001855_IFCB124.adc\" ,\n",
    "                hdr_path= \"../../IFCBData/DenseAlex/nauset/D20240402T001855_IFCB124.hdr\",\n",
    "                class_csv_path= None,\n",
    "                drop_zero_roi= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c4fe7c3-7957-4532-9159-6ecbc4f7fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RoiNumber   ADCtime   RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0          1  3.499807  3.527602     0.077693         0.000000   \n",
      "1          2  3.655534  3.675564     0.158394         0.080701   \n",
      "2          3  3.918805  3.939672     0.239894         0.081500   \n",
      "3          4  4.007731  4.028700     0.321487         0.081593   \n",
      "4          5  4.268916  4.290599     0.403576         0.082090   \n",
      "\n",
      "   VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0        0.014375         76        96   868   814  \n",
      "1        0.014655         44        64   908   374  \n",
      "2        0.015416        164       352   620   710  \n",
      "3        0.015447         44        72   892   494  \n",
      "4        0.016196        116       208   780   462  \n"
     ]
    }
   ],
   "source": [
    "print(zeroroi_out_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c9d0b58-0ec9-4569-afa0-856ebe6c820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroroi_out_dfsub = zeroroi_out_df[zeroroi_out_df[\"RoiHeight\"] == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c1a46e3-4fe3-48dc-b960-43df57e0a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "2983       2984   338.992805   339.019583   218.932951         0.083559   \n",
      "4110       4111   467.703231   467.732188   301.716597         0.083819   \n",
      "4130       4131   470.330514   470.358542   303.178819         0.080972   \n",
      "7300       7301   898.968555   899.006458   534.672118         0.081042   \n",
      "8246       8247  1070.022962  1070.065139   604.098264         0.081944   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "2983        0.500361          0         0     0     0  \n",
      "4110        0.691732          0         0     0     0  \n",
      "4130        0.696582          0         0     0     0  \n",
      "7300        1.518060          0         0     0     0  \n",
      "8246        1.941529          0         0     0     0  \n"
     ]
    }
   ],
   "source": [
    "print(zeroroi_out_dfsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec876820-9015-41f9-8bd5-96cba42ea164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e5dc98f-b5d9-4281-aa5f-3ae28d26d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf= pd.read_csv(\"../../IFCBData/AlexandriumTest/D20240423T013135_IFCB124.adc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83f49fb4-9866-453d-b97c-01a37688c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  7.2385623  0.011560917  0.23869514  0.0028413534  0.005519986  \\\n",
      "0  2   7.845012     0.110034    1.123450      0.003033     0.006526   \n",
      "1  3   7.955851     0.040947    0.646555      0.002875     0.005762   \n",
      "2  4   8.042567     0.008063    0.003243      0.002744     0.004782   \n",
      "3  5   8.144744     0.001699    0.005319      0.002816     0.004810   \n",
      "4  5   8.144744     0.001699    0.005319      0.002816     0.004810   \n",
      "\n",
      "   0.16925335  2.4983597  0.01557827  0.019361973  ...  614  128  100      0  \\\n",
      "0    0.573065   3.516121    0.015638     0.019433  ...  542  232  156  12800   \n",
      "1    0.405929   3.519251    0.015655     0.019457  ...  694  160  132  48992   \n",
      "2    0.152726   0.115840    0.015476     0.019307  ...  446  136   84  70112   \n",
      "3    0.038433   0.020294    0.015209     0.018961  ...  638   64   36  81536   \n",
      "4    0.038433   0.020294    0.015209     0.018961  ...  822   72   44  83840   \n",
      "\n",
      "   0.1  0.2  0.3  0.4  7.256404079861111  0.07120442708333333  \n",
      "0    0    0    0    0           7.863466             0.153535  \n",
      "1    0    0    0    0           7.973433             0.235321  \n",
      "2    0    0    0    0           8.059850             0.316593  \n",
      "3    0    0    0    0           8.162919             0.398602  \n",
      "4    0    0    0    0           8.162919             0.398602  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd17da-5e4c-448b-abc0-9cc17c75106b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
