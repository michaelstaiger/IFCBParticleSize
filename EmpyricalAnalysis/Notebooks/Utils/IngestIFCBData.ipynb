{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d65a6a-c6be-4af4-bc2a-ed1398746712",
   "metadata": {},
   "source": [
    "### Ingests a single set of ADC, HDR and Class files \n",
    "\n",
    "Takes the required info from each file and creates single merged file \n",
    "Logic\n",
    "1) Parse ADCFileFormat from .hdr to get column names\n",
    "2) Load .adc with those headers\n",
    "3) Add RoiNumber to ADC as 1 - N\n",
    "4) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 -- this removes zero roi triggers so we can merge with class file on roi number\n",
    "5) Add InhibitTimeDiff = diff(InhibitTime).fillna(0) -- useful for understanding sample density\n",
    "6) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240  -- needed for concentration estimates and also useful for understanding sample density\n",
    "7) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23) -- used to merge with adc file\n",
    "8) Merge class_df with ADC-derived columns on RoiNumber\n",
    "9) Return merged_df (and adc_df, class_df)\n",
    "\n",
    "This gives you dataset of all rois with class scores and associated ADC metadata\n",
    "\n",
    "#### NOTE: Has been updated use the second version that is below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65a3ec-f4f3-4cb8-a6f7-7cc34d035d41",
   "metadata": {},
   "source": [
    "# Version 1\n",
    "saved for future incase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2145f1b4-301d-4bb1-a7e3-88bd86c4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: str,\n",
    "                drop_zero_roi: bool = True):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Parse ADCFileFormat from .hdr to get column names\n",
    "      2) Load .adc with those headers\n",
    "      3) Add RoiNumber to ADC as 1..N\n",
    "      4) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 (optionally)\n",
    "      5) Add InhibitTimeDiff = diff(InhibitTime).fillna(0)\n",
    "      6) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240\n",
    "      7) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23)\n",
    "      8) Merge class_df with ADC-derived columns on RoiNumber\n",
    "      9) Return merged_df (and adc_df, class_df)\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path)\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(\"ADCFileFormat not found in header file.\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        # ensure numeric in case strings slipped in\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff().fillna(0)\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # 7) Load class CSV + extract RoiNumber from pid\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    if 'pid' not in class_df.columns:\n",
    "        raise ValueError(\"Expected 'pid' column in class CSV to extract RoiNumber.\")\n",
    "    class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # 8) Merge on RoiNumber\n",
    "    cols_to_keep = ['RoiNumber', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed'] ## can add or remove col here depending on what you want\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    merged_df = class_df.merge(adc_df[cols_to_keep], on='RoiNumber', how='left')\n",
    "\n",
    "    # 9) Return\n",
    "    return merged_df, adc_df, class_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cec2d-252f-4a06-bbe4-9f8bfeeb1c68",
   "metadata": {},
   "source": [
    "## Loops over a directory and outputs a merged directory\n",
    "\n",
    "wrapper for the ingest_ifcb function that merges based on the initial string of the file names and writes out merged datasets to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08e1e6a4-5051-4f72-9927-bc3ebb4a6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "def ingest_ifcb_directory(directory: str,\n",
    "                          drop_zero_roi: bool = True,\n",
    "                          save_path: str | None = None) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loop over a directory, find sets of .adc, .hdr, and class CSV files\n",
    "    that share the same IFCB run prefix, and return merged dataframes.\n",
    "\n",
    "    Args:\n",
    "        directory: Folder containing IFCB .adc, .hdr, and class CSV files.\n",
    "        drop_zero_roi: Passed to ingest_ifcb().\n",
    "        save_path: Optional folder to save merged CSVs.\n",
    "                   If None, files are saved in the source directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: { prefix : merged_dataframe }\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_files = list(directory.glob(\"*.adc\"))\n",
    "    hdr_files = list(directory.glob(\"*.hdr\"))\n",
    "    class_files = list(directory.glob(\"*class*.csv\"))\n",
    "\n",
    "    # Build file lookup maps\n",
    "    adc_map   = {f.stem: f for f in adc_files}\n",
    "    hdr_map   = {f.stem: f for f in hdr_files}\n",
    "    class_map = {f.stem.replace(\"_class_vNone\", \"\").replace(\"_class\", \"\"): f\n",
    "                 for f in class_files}\n",
    "\n",
    "    prefixes = set(adc_map.keys()) | set(hdr_map.keys()) | set(class_map.keys())\n",
    "\n",
    "    merged_results = {}\n",
    "\n",
    "    for prefix in sorted(prefixes):\n",
    "        adc_path   = adc_map.get(prefix)\n",
    "        hdr_path   = hdr_map.get(prefix)\n",
    "        class_path = class_map.get(prefix)\n",
    "\n",
    "        # Require complete sets\n",
    "        if not (adc_path and hdr_path and class_path):\n",
    "            print(f\"Skipping {prefix}: incomplete set of files.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        merged_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=adc_path,\n",
    "            hdr_path=hdr_path,\n",
    "            class_csv_path=class_path,\n",
    "            drop_zero_roi=drop_zero_roi\n",
    "        )\n",
    "\n",
    "        merged_results[prefix] = merged_df\n",
    "\n",
    "        # Save output to designated location\n",
    "        outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        merged_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved merged file â†’ {outfile}\")\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59245ed6-33e8-4e76-ab1f-556d1e8bfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac68709-f90c-4e6a-849f-9d5756356e6f",
   "metadata": {},
   "source": [
    "### Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "942fa757-72b7-4da7-aad0-a9467d78e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/spawn/zygotes/\"\n",
    "merged_dir = \"../../IFCBData/spawn/zygotes/merged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "061e8152-ae41-4838-8fb0-ab83dcbe3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240501T200201_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429804-cf96-4e37-9896-4b4f702fa89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1436e46e-5127-488a-b2fe-0ff0bb763dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38c7e0db-e7c0-49d4-9a66-ce3b8f534a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0             2     4.931790     4.953893     0.083047         0.000000   \n",
      "1             3     5.104920     5.127059     0.166803         0.083757   \n",
      "2             4     5.774158     5.796293     0.249392         0.082589   \n",
      "3             5     5.865553     5.888199     0.333301         0.083908   \n",
      "4             6     5.952413     5.972958     0.414779         0.081478   \n",
      "...         ...          ...          ...          ...              ...   \n",
      "6378       6786  1198.809496  1198.831528   517.552604         0.083160   \n",
      "6379       6787  1199.135671  1199.157500   517.634792         0.082187   \n",
      "6380       6789  1199.493438  1199.514583   517.801215         0.166424   \n",
      "6381       6790  1200.150306  1200.174167   517.885764         0.084549   \n",
      "6382       6791  1200.525941  1200.548333   517.968507         0.082743   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0           0.020295         44        88   948   534  \n",
      "1           0.020668        188       208   764   630  \n",
      "2           0.023112         84       104   892   782  \n",
      "3           0.023145        204       248   740   342  \n",
      "4           0.023159        204       240   748   398  \n",
      "...              ...        ...       ...   ...   ...  \n",
      "6378        2.838662         60        96   900   782  \n",
      "6379        2.839678         68        96   876   782  \n",
      "6380        2.840472         44        64   932   758  \n",
      "6381        2.842868         68       120   884   838  \n",
      "6382        2.844083         68       144   884   630  \n",
      "\n",
      "[6383 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87504f37-49ba-43cf-8cef-1760e1d0918d",
   "metadata": {},
   "source": [
    "# Version2\n",
    "\n",
    "## USE THIS VERSION: Class file optional Versions -- same logic just now can handle missing class files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac70280-fc63-41ed-bbe3-f6f839803bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bee5b-fdf2-4796-b979-fda52b04872b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfa228bb-ca2f-443f-8744-82dd1680f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: Optional[str] = None,\n",
    "                drop_zero_roi: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    Returns:\n",
    "        merged_df: \n",
    "            - if class provided & exists: class_df merged with adc-derived columns on RoiNumber\n",
    "            - else: adc-derived dataframe containing RoiNumber + derived columns (and ROI geometry if present)\n",
    "        adc_df: ADC dataframe with parsed headers + derived columns\n",
    "        class_df: class dataframe if loaded, else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff().fillna(0)\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber','ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed'] ## can add more here if you want other things not sure why chat started cutting stuff out\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        merged_df = class_df.merge(adc_out, on='RoiNumber', how='left')\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f0bbb1-7d9b-420f-b04b-a737d201cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process a folder of IFCB files. For each prefix:\n",
    "      - requires .adc and .hdr\n",
    "      - class CSV is optional\n",
    "\n",
    "    Class CSV matching (more flexible):\n",
    "      - We derive prefixes from .adc/.hdr stems\n",
    "      - For each prefix, we look for CSVs that:\n",
    "          1) start with that prefix\n",
    "          2) contain 'class' (case-insensitive)\n",
    "          3) AND (if class_suffixes provided) match ANY of the provided patterns/suffixes\n",
    "\n",
    "    `class_suffixes` can contain:\n",
    "      - exact suffixes like \"_class.csv\"\n",
    "      - wildcard patterns like \"_class*.csv\", \"*class*.csv\", \"_class_v*.csv\"\n",
    "      - If None or empty, we auto-accept ANY \"*class*.csv\" that starts with the prefix.\n",
    "\n",
    "    If multiple class CSVs match a prefix:\n",
    "      - if prefer_newest_class_file=True, choose most recently modified\n",
    "      - else choose lexicographically first (stable)\n",
    "\n",
    "    Writes outputs to save_path (or the input directory if None).\n",
    "\n",
    "    Returns:\n",
    "      dict {prefix: output_df}\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    # Only process prefixes that actually have adc+hdr\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    # Candidate class CSVs: anything with 'class' in the filename\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        \"\"\"\n",
    "        Match logic:\n",
    "          - If class_suffixes is None/empty: accept any class candidate starting with prefix.\n",
    "          - Else: for each token in class_suffixes:\n",
    "              * If token has wildcards -> use fnmatch against:\n",
    "                    - f\"{prefix}{token}\"  (token interpreted as suffix/pattern)\n",
    "                    - token itself (in case user passes full pattern)\n",
    "              * If token has no wildcards -> treat as suffix and require filename.endswith(token)\n",
    "        \"\"\"\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class_map keyed by prefix\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "        class_path = class_map.get(prefix)  # may be None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # Save with different suffix depending on whether class exists\n",
    "        if class_df is not None:\n",
    "            outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac463b8-b1c6-42af-b927-1beea9b886cd",
   "metadata": {},
   "source": [
    "## Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51889411-2e8c-4bdf-a96b-7d8dc2a85a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/AlexandriumTest/\"\n",
    "merged_dir = \"../../IFCBData/AlexandriumTest/keepzeroroinoclass/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f264f715-d296-4d0e-9847-8f5277551222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240420T095637_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240420T095637_IFCB124_merged.csv\n",
      "Processing D20240423T013135_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240423T013135_IFCB124_merged.csv\n",
      "Processing D20240429T195718_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240429T195718_IFCB124_merged.csv\n",
      "Processing D20240429T213320_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240429T213320_IFCB124_merged.csv\n",
      "Processing D20240501T235832_IFCB124 (class=yes)...\n",
      "Saved: ../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240501T235832_IFCB124_merged.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   #class_suffixes=\"_class_scores.csv\", # add this in if you care about class scores or if non standard naming here\n",
    "                                    drop_zero_roi= False \n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98704bfe-f0e5-49c2-ab53-5d03b237ab07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a05f7de8-f6ec-4b48-8f2c-09d70db26b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/AlexandriumTest/keepzeroroinoclass/D20240420T095637_IFCB124_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bcf4236-3228-41bd-a154-cd8b0353c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              pid  Alexandrium_catenella  \\\n",
      "0  D20240420T095637_IFCB124_00002               0.000000   \n",
      "1  D20240420T095637_IFCB124_00003               0.000000   \n",
      "2  D20240420T095637_IFCB124_00004               0.803000   \n",
      "3  D20240420T095637_IFCB124_00005               0.000007   \n",
      "4  D20240420T095637_IFCB124_00006               0.921400   \n",
      "\n",
      "   Alexandrium_catenella_TAG_2cell_TAG_chain  \\\n",
      "0                                   0.000000   \n",
      "1                                   0.000004   \n",
      "2                                   0.011060   \n",
      "3                                   0.000022   \n",
      "4                                   0.003223   \n",
      "\n",
      "   Alexandrium_catenella_TAG_4cell_TAG_chain  \\\n",
      "0                                        0.0   \n",
      "1                                        0.0   \n",
      "2                                        0.0   \n",
      "3                                        0.0   \n",
      "4                                        0.0   \n",
      "\n",
      "   Alexandrium_catenella_TAG_dividing  Alexandrium_catenella_TAG_fusing  \\\n",
      "0                        0.000000e+00                      0.000000e+00   \n",
      "1                        6.000000e-08                      6.000000e-08   \n",
      "2                        3.262000e-04                      5.140000e-03   \n",
      "3                        1.810000e-05                      3.950000e-05   \n",
      "4                        1.291000e-04                      1.739500e-03   \n",
      "\n",
      "     Amoeba    Amylax  Apedinella  Asterionellopsis_glacialis  ...  RoiNumber  \\\n",
      "0  0.000000  0.000000    0.000000                0.000000e+00  ...          2   \n",
      "1  0.001628  0.000000    0.000000                1.260000e-05  ...          3   \n",
      "2  0.000037  0.000035    0.000002                3.160000e-06  ...          4   \n",
      "3  0.000030  0.000139    0.000000                8.300000e-07  ...          5   \n",
      "4  0.000001  0.000015    0.000006                2.440000e-06  ...          6   \n",
      "\n",
      "    ADCtime   RunTime  InhibitTime  InhibitTimeDiff  VolumeAnalyzed  \\\n",
      "0  7.975714  8.002049     0.075228         0.075228        0.033028   \n",
      "1  8.841708  8.862817     0.905243         0.830015        0.033157   \n",
      "2  8.882137  8.931997     0.970729         0.065486        0.033172   \n",
      "3  8.951330  9.007261     1.038776         0.068047        0.033202   \n",
      "4  9.027408  9.075471     1.088641         0.049865        0.033278   \n",
      "\n",
      "   RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0         44        80   836   598  \n",
      "1         52        88   860   470  \n",
      "2        132       160   788   390  \n",
      "3        132       152   780   662  \n",
      "4        124       152   788   214  \n",
      "\n",
      "[5 rows x 147 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27d467-606f-46f2-9d9d-6d6a518fc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c546318-b6b5-441b-8e41-1df2ec01827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroroi_out_df, zeroroi_adc_df, testy_df = ingest_ifcb(adc_path= \"../../IFCBData/DenseAlex/nauset/D20240402T001855_IFCB124.adc\" ,\n",
    "                hdr_path= \"../../IFCBData/DenseAlex/nauset/D20240402T001855_IFCB124.hdr\",\n",
    "                class_csv_path= None,\n",
    "                drop_zero_roi= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c4fe7c3-7957-4532-9159-6ecbc4f7fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RoiNumber   ADCtime   RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0          1  3.499807  3.527602     0.077693         0.000000   \n",
      "1          2  3.655534  3.675564     0.158394         0.080701   \n",
      "2          3  3.918805  3.939672     0.239894         0.081500   \n",
      "3          4  4.007731  4.028700     0.321487         0.081593   \n",
      "4          5  4.268916  4.290599     0.403576         0.082090   \n",
      "\n",
      "   VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0        0.014375         76        96   868   814  \n",
      "1        0.014655         44        64   908   374  \n",
      "2        0.015416        164       352   620   710  \n",
      "3        0.015447         44        72   892   494  \n",
      "4        0.016196        116       208   780   462  \n"
     ]
    }
   ],
   "source": [
    "print(zeroroi_out_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c9d0b58-0ec9-4569-afa0-856ebe6c820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroroi_out_dfsub = zeroroi_out_df[zeroroi_out_df[\"RoiHeight\"] == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c1a46e3-4fe3-48dc-b960-43df57e0a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "2983       2984   338.992805   339.019583   218.932951         0.083559   \n",
      "4110       4111   467.703231   467.732188   301.716597         0.083819   \n",
      "4130       4131   470.330514   470.358542   303.178819         0.080972   \n",
      "7300       7301   898.968555   899.006458   534.672118         0.081042   \n",
      "8246       8247  1070.022962  1070.065139   604.098264         0.081944   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "2983        0.500361          0         0     0     0  \n",
      "4110        0.691732          0         0     0     0  \n",
      "4130        0.696582          0         0     0     0  \n",
      "7300        1.518060          0         0     0     0  \n",
      "8246        1.941529          0         0     0     0  \n"
     ]
    }
   ],
   "source": [
    "print(zeroroi_out_dfsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec876820-9015-41f9-8bd5-96cba42ea164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e5dc98f-b5d9-4281-aa5f-3ae28d26d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf= pd.read_csv(\"../../IFCBData/AlexandriumTest/D20240423T013135_IFCB124.adc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83f49fb4-9866-453d-b97c-01a37688c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  7.2385623  0.011560917  0.23869514  0.0028413534  0.005519986  \\\n",
      "0  2   7.845012     0.110034    1.123450      0.003033     0.006526   \n",
      "1  3   7.955851     0.040947    0.646555      0.002875     0.005762   \n",
      "2  4   8.042567     0.008063    0.003243      0.002744     0.004782   \n",
      "3  5   8.144744     0.001699    0.005319      0.002816     0.004810   \n",
      "4  5   8.144744     0.001699    0.005319      0.002816     0.004810   \n",
      "\n",
      "   0.16925335  2.4983597  0.01557827  0.019361973  ...  614  128  100      0  \\\n",
      "0    0.573065   3.516121    0.015638     0.019433  ...  542  232  156  12800   \n",
      "1    0.405929   3.519251    0.015655     0.019457  ...  694  160  132  48992   \n",
      "2    0.152726   0.115840    0.015476     0.019307  ...  446  136   84  70112   \n",
      "3    0.038433   0.020294    0.015209     0.018961  ...  638   64   36  81536   \n",
      "4    0.038433   0.020294    0.015209     0.018961  ...  822   72   44  83840   \n",
      "\n",
      "   0.1  0.2  0.3  0.4  7.256404079861111  0.07120442708333333  \n",
      "0    0    0    0    0           7.863466             0.153535  \n",
      "1    0    0    0    0           7.973433             0.235321  \n",
      "2    0    0    0    0           8.059850             0.316593  \n",
      "3    0    0    0    0           8.162919             0.398602  \n",
      "4    0    0    0    0           8.162919             0.398602  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd17da-5e4c-448b-abc0-9cc17c75106b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
