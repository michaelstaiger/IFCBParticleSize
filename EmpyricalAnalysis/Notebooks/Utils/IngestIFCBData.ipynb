{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d65a6a-c6be-4af4-bc2a-ed1398746712",
   "metadata": {},
   "source": [
    "### Ingests a single set of ADC, HDR and Class files \n",
    "\n",
    "Takes the required info from each file and creates single merged file \n",
    "Logic Updated to version 3  to contain new logic, class flexibility, and zero roi options\n",
    "1) Parse ADCFileFormat from .hdr to get column names\n",
    "2) Load .adc with those headers\n",
    "3) Add RoiNumber to ADC as 1 - N\n",
    "4) apply false trigger filterring\n",
    "5) Tag all rois with RoiX=RoiY=RoiHeight=RoiWidth=0  as IsZeroRoi = 1,  Optionally:  Remove these rows if only care about class \n",
    "6) Add InhibitTimeDiff = diff(InhibitTime).fillna(0) -- useful for understanding sample density\n",
    "7) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240  -- needed for concentration estimates and also useful for understanding sample density\n",
    "8) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23) -- used to merge with adc file - left merged on ADC File\n",
    "9) Merge class_df with ADC-derived columns on RoiNumber - for zero rois fill all class scores with 0s\n",
    "10) Return merged_df (and adc_df, class_df)\n",
    "\n",
    "This gives you dataset of all rois with class scores and associated ADC metadata\n",
    "\n",
    " NOTE: Has been updated use the  version that is below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f710b7b-319d-40fe-8162-01857a203d60",
   "metadata": {},
   "source": [
    "# Currentlly recomend using Versoion 3 at the bottom for most flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65a3ec-f4f3-4cb8-a6f7-7cc34d035d41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Version 1 Dont use this !\n",
    "saved for future incase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2145f1b4-301d-4bb1-a7e3-88bd86c4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: str,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Parse ADCFileFormat from .hdr to get column names\n",
    "      2) Load .adc with those headers\n",
    "      3) Add RoiNumber to ADC as 1..N\n",
    "      4) (NEW) Drop false trigger if present: RunTime < 0.25 AND zero ROI\n",
    "      5) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 (optionally)\n",
    "      6) Add InhibitTimeDiff with special first-row rule\n",
    "      7) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240\n",
    "      8) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23)\n",
    "      9) Merge class_df with ADC-derived columns on RoiNumber\n",
    "      10) Return merged_df (and adc_df, class_df)\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path)\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(\"ADCFileFormat not found in header file.\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger if present (before any other filtering) ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            # Drop it if present; keep original RoiNumber values; don't reset index\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (first real trigger uses cumulative inhibit time)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # First remaining row (first real trigger): InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # Safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # 7) Load class CSV + extract RoiNumber from pid\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    if 'pid' not in class_df.columns:\n",
    "        raise ValueError(\"Expected 'pid' column in class CSV to extract RoiNumber.\")\n",
    "    class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # 8) Merge on RoiNumber\n",
    "    cols_to_keep = ['RoiNumber', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    merged_df = class_df.merge(adc_df[cols_to_keep], on='RoiNumber', how='left')\n",
    "\n",
    "    # 9) Return\n",
    "    return merged_df, adc_df, class_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cec2d-252f-4a06-bbe4-9f8bfeeb1c68",
   "metadata": {},
   "source": [
    "## Loops over a directory and outputs a merged directory\n",
    "\n",
    "wrapper for the ingest_ifcb function that merges based on the initial string of the file names and writes out merged datasets to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08e1e6a4-5051-4f72-9927-bc3ebb4a6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "import fnmatch\n",
    "\n",
    "def ingest_ifcb_directory(directory: str,\n",
    "                          drop_zero_roi: bool = True,\n",
    "                          save_path: str | None = None,\n",
    "                          # ---- NEW (optional) ----\n",
    "                          drop_false_trigger: bool = True,\n",
    "                          false_trigger_runtime_s: float = 0.25,\n",
    "                          class_suffixes: Optional[tuple] = None,\n",
    "                          prefer_newest_class_file: bool = True\n",
    "                          ) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loop over a directory, find sets of .adc, .hdr, and class CSV files\n",
    "    that share the same IFCB run prefix, and return merged dataframes.\n",
    "\n",
    "    Minimal changes:\n",
    "      - class file detection is now prefix-based and flexible (handles variable suffixes)\n",
    "      - passes drop_false_trigger + false_trigger_runtime_s into ingest_ifcb\n",
    "\n",
    "    Args:\n",
    "        directory: Folder containing IFCB .adc, .hdr, and class CSV files.\n",
    "        drop_zero_roi: Passed to ingest_ifcb().\n",
    "        save_path: Optional folder to save merged CSVs.\n",
    "        drop_false_trigger: If True, drop early false trigger(s) in ingest_ifcb.\n",
    "        false_trigger_runtime_s: Runtime cutoff for false trigger rule.\n",
    "        class_suffixes: Optional patterns/suffixes for class files.\n",
    "            - If None (default): accept any CSV that starts with prefix and contains 'class'\n",
    "            - If provided: may include exact suffixes or wildcard patterns, e.g. (\"_class*.csv\",)\n",
    "        prefer_newest_class_file: If multiple class files match, choose newest (True) or name-sorted (False).\n",
    "\n",
    "    Returns:\n",
    "        dict: { prefix : merged_dataframe }\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_files = list(directory.glob(\"*.adc\"))\n",
    "    hdr_files = list(directory.glob(\"*.hdr\"))\n",
    "    class_files = list(directory.glob(\"*class*.csv\"))\n",
    "\n",
    "    # Build file lookup maps\n",
    "    adc_map = {f.stem: f for f in adc_files}\n",
    "    hdr_map = {f.stem: f for f in hdr_files}\n",
    "\n",
    "    # Only consider prefixes that have adc+hdr (required)\n",
    "    prefixes = sorted(set(adc_map.keys()).intersection(set(hdr_map.keys())))\n",
    "\n",
    "    def _class_matches(prefix: str, filename: str) -> bool:\n",
    "        # Must start with the prefix (strong constraint)\n",
    "        if not filename.startswith(prefix):\n",
    "            return False\n",
    "\n",
    "        # If no suffix patterns provided, accept any \"class\" csv starting with prefix\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        # Otherwise allow exact suffixes OR wildcard patterns\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                # interpret token as a suffix pattern, e.g. \"_class*.csv\"\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                # interpret token as exact suffix\n",
    "                if filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class map by searching best match per prefix\n",
    "    class_map = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = [f for f in class_files if _class_matches(prefix, f.name)]\n",
    "        if matches:\n",
    "            best = max(matches, key=lambda x: x.stat().st_mtime) if prefer_newest_class_file else sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    merged_results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map.get(prefix)\n",
    "        hdr_path = hdr_map.get(prefix)\n",
    "        class_path = class_map.get(prefix)\n",
    "\n",
    "        # Require class file too (matches your original behavior)\n",
    "        if not class_path:\n",
    "            print(f\"Skipping {prefix}: missing class CSV.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        merged_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path),\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            # ---- pass-through new logic ----\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s\n",
    "        )\n",
    "\n",
    "        merged_results[prefix] = merged_df\n",
    "\n",
    "        # Save output to designated location\n",
    "        outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        merged_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved merged file â†’ {outfile}\")\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59245ed6-33e8-4e76-ab1f-556d1e8bfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac68709-f90c-4e6a-849f-9d5756356e6f",
   "metadata": {},
   "source": [
    "### Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "942fa757-72b7-4da7-aad0-a9467d78e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/AlexandriumTest/\"\n",
    "merged_dir = \"../../IFCBData/AlexandriumTest/newmerged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "061e8152-ae41-4838-8fb0-ab83dcbe3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240501T200201_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429804-cf96-4e37-9896-4b4f702fa89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1436e46e-5127-488a-b2fe-0ff0bb763dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38c7e0db-e7c0-49d4-9a66-ce3b8f534a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0             2     4.931790     4.953893     0.083047         0.000000   \n",
      "1             3     5.104920     5.127059     0.166803         0.083757   \n",
      "2             4     5.774158     5.796293     0.249392         0.082589   \n",
      "3             5     5.865553     5.888199     0.333301         0.083908   \n",
      "4             6     5.952413     5.972958     0.414779         0.081478   \n",
      "...         ...          ...          ...          ...              ...   \n",
      "6378       6786  1198.809496  1198.831528   517.552604         0.083160   \n",
      "6379       6787  1199.135671  1199.157500   517.634792         0.082187   \n",
      "6380       6789  1199.493438  1199.514583   517.801215         0.166424   \n",
      "6381       6790  1200.150306  1200.174167   517.885764         0.084549   \n",
      "6382       6791  1200.525941  1200.548333   517.968507         0.082743   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0           0.020295         44        88   948   534  \n",
      "1           0.020668        188       208   764   630  \n",
      "2           0.023112         84       104   892   782  \n",
      "3           0.023145        204       248   740   342  \n",
      "4           0.023159        204       240   748   398  \n",
      "...              ...        ...       ...   ...   ...  \n",
      "6378        2.838662         60        96   900   782  \n",
      "6379        2.839678         68        96   876   782  \n",
      "6380        2.840472         44        64   932   758  \n",
      "6381        2.842868         68       120   884   838  \n",
      "6382        2.844083         68       144   884   630  \n",
      "\n",
      "[6383 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87504f37-49ba-43cf-8cef-1760e1d0918d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Version2\n",
    "\n",
    "## Class file optional Versions -- same logic just now can handle missing class files \n",
    "## Allows for skipping first false trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac70280-fc63-41ed-bbe3-f6f839803bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bee5b-fdf2-4796-b979-fda52b04872b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfa228bb-ca2f-443f-8744-82dd1680f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: Optional[str] = None,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25\n",
    "                ) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    NEW:\n",
    "      - drops early false trigger(s) if: RunTime < false_trigger_runtime_s AND (RoiX=RoiY=RoiHeight=RoiWidth=0)\n",
    "      - recomputes InhibitTimeDiff after dropping false triggers:\n",
    "            first row: InhibitTimeDiff = InhibitTime\n",
    "            later rows: InhibitTimeDiff = diff(InhibitTime)\n",
    "\n",
    "    Returns:\n",
    "        merged_df:\n",
    "            - if class provided & exists: class_df merged with adc-derived columns on RoiNumber\n",
    "            - else: adc-derived dataframe containing RoiNumber + derived columns (and ROI geometry if present)\n",
    "        adc_df: ADC dataframe with parsed headers + derived columns\n",
    "        class_df: class dataframe if loaded, else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger(s) BEFORE drop_zero_roi ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            # numeric coercion for robust comparisons\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]  # preserve RoiNumber, don't reset index\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (with special first-row rule after filtering)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # first remaining row: InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0.0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber', 'ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        merged_df = class_df.merge(adc_out, on='RoiNumber', how='left')\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "24f0bbb1-7d9b-420f-b04b-a737d201cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    "    # ---- existing options ----\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25,\n",
    "    # ---- NEW (minimal) ----\n",
    "    use_class_files: bool = True,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process a folder of IFCB files. For each prefix:\n",
    "      - requires .adc and .hdr\n",
    "      - class CSV is optional\n",
    "\n",
    "    NEW:\n",
    "      - if use_class_files=False, class CSVs are ignored even if present\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    # Only process prefixes that actually have adc+hdr\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    # Candidate class CSVs: anything with 'class' in the filename\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class_map keyed by prefix\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "\n",
    "        # ---- MINIMAL CHANGE: ignore class files if requested ----\n",
    "        class_path = class_map.get(prefix) if use_class_files else None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s,\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # Save with different suffix depending on whether class exists\n",
    "        if class_df is not None:\n",
    "            outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac463b8-b1c6-42af-b927-1beea9b886cd",
   "metadata": {},
   "source": [
    "## Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51889411-2e8c-4bdf-a96b-7d8dc2a85a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/DenseAlex/nauset/\"\n",
    "merged_dir = \"../../IFCBData/DenseAlex/nauset/zeroRoiMerge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f264f715-d296-4d0e-9847-8f5277551222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240402T001855_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T001855_IFCB124_adc_only.csv\n",
      "Processing D20240402T004255_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T004255_IFCB124_adc_only.csv\n",
      "Processing D20240402T010656_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T010656_IFCB124_adc_only.csv\n",
      "Processing D20240402T013056_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T013056_IFCB124_adc_only.csv\n",
      "Processing D20240402T015457_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T015457_IFCB124_adc_only.csv\n",
      "Processing D20240402T021857_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T021857_IFCB124_adc_only.csv\n",
      "Processing D20240402T024258_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T024258_IFCB124_adc_only.csv\n",
      "Processing D20240402T030659_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T030659_IFCB124_adc_only.csv\n",
      "Processing D20240402T033059_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T033059_IFCB124_adc_only.csv\n",
      "Processing D20240402T035500_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T035500_IFCB124_adc_only.csv\n",
      "Processing D20240402T041916_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T041916_IFCB124_adc_only.csv\n",
      "Processing D20240402T044316_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T044316_IFCB124_adc_only.csv\n",
      "Processing D20240402T050717_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T050717_IFCB124_adc_only.csv\n",
      "Processing D20240402T053118_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T053118_IFCB124_adc_only.csv\n",
      "Processing D20240402T055518_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T055518_IFCB124_adc_only.csv\n",
      "Processing D20240402T061919_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T061919_IFCB124_adc_only.csv\n",
      "Processing D20240402T064320_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T064320_IFCB124_adc_only.csv\n",
      "Processing D20240402T070721_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T070721_IFCB124_adc_only.csv\n",
      "Processing D20240402T073122_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T073122_IFCB124_adc_only.csv\n",
      "Processing D20240402T075523_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T075523_IFCB124_adc_only.csv\n",
      "Processing D20240402T081924_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T081924_IFCB124_adc_only.csv\n",
      "Processing D20240402T084324_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T084324_IFCB124_adc_only.csv\n",
      "Processing D20240402T090725_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T090725_IFCB124_adc_only.csv\n",
      "Processing D20240402T093125_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T093125_IFCB124_adc_only.csv\n",
      "Processing D20240402T095526_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T095526_IFCB124_adc_only.csv\n",
      "Processing D20240402T101927_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T101927_IFCB124_adc_only.csv\n",
      "Processing D20240402T104327_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T104327_IFCB124_adc_only.csv\n",
      "Processing D20240402T110728_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T110728_IFCB124_adc_only.csv\n",
      "Processing D20240402T113128_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T113128_IFCB124_adc_only.csv\n",
      "Processing D20240402T115529_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T115529_IFCB124_adc_only.csv\n",
      "Processing D20240402T121929_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T121929_IFCB124_adc_only.csv\n",
      "Processing D20240402T124330_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T124330_IFCB124_adc_only.csv\n",
      "Processing D20240402T130730_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T130730_IFCB124_adc_only.csv\n",
      "Processing D20240402T133131_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T133131_IFCB124_adc_only.csv\n",
      "Processing D20240402T135532_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T135532_IFCB124_adc_only.csv\n",
      "Processing D20240402T141952_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T141952_IFCB124_adc_only.csv\n",
      "Processing D20240402T144353_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T144353_IFCB124_adc_only.csv\n",
      "Processing D20240402T150753_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T150753_IFCB124_adc_only.csv\n",
      "Processing D20240402T153155_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T153155_IFCB124_adc_only.csv\n",
      "Processing D20240402T155556_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T155556_IFCB124_adc_only.csv\n",
      "Processing D20240402T161956_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T161956_IFCB124_adc_only.csv\n",
      "Processing D20240402T164357_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T164357_IFCB124_adc_only.csv\n",
      "Processing D20240402T170758_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T170758_IFCB124_adc_only.csv\n",
      "Processing D20240402T173158_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T173158_IFCB124_adc_only.csv\n",
      "Processing D20240402T175559_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T175559_IFCB124_adc_only.csv\n",
      "Processing D20240402T182050_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T182050_IFCB124_adc_only.csv\n",
      "Processing D20240402T184451_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T184451_IFCB124_adc_only.csv\n",
      "Processing D20240402T190851_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T190851_IFCB124_adc_only.csv\n",
      "Processing D20240402T193252_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T193252_IFCB124_adc_only.csv\n",
      "Processing D20240402T195652_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T195652_IFCB124_adc_only.csv\n",
      "Processing D20240402T204252_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T204252_IFCB124_adc_only.csv\n",
      "Processing D20240402T210651_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T210651_IFCB124_adc_only.csv\n",
      "Processing D20240402T213052_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T213052_IFCB124_adc_only.csv\n",
      "Processing D20240402T215453_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T215453_IFCB124_adc_only.csv\n",
      "Processing D20240402T221910_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T221910_IFCB124_adc_only.csv\n",
      "Processing D20240402T224311_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T224311_IFCB124_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                    use_class_files=False\n",
    "                                    #class_suffixes=\"_class_scores.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98704bfe-f0e5-49c2-ab53-5d03b237ab07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "864c6a6c-83e2-46a1-af0a-9e12e71ad9fa",
   "metadata": {},
   "source": [
    "# VERSION 3 \n",
    "## Includes zero roi logic and flexible class inputs\n",
    "### allows for zero roi maintained and give null values for class scores also included bolian isZeroRoi with 1 = yes is zero roi and 0 = not zero roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "51fad1d7-bae1-4498-89e6-a111f915e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(\n",
    "    adc_path: str,\n",
    "    hdr_path: str,\n",
    "    class_csv_path: Optional[str] = None,\n",
    "    drop_zero_roi: bool = True,\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    Updates:\n",
    "      - Adds IsZeroRoi (1 if RoiX=RoiY=RoiHeight=RoiWidth=0 else 0)\n",
    "      - Drops early false trigger(s) BEFORE drop_zero_roi\n",
    "      - Recomputes InhibitTimeDiff after filtering:\n",
    "            first row: InhibitTimeDiff = InhibitTime\n",
    "            later rows: InhibitTimeDiff = diff(InhibitTime)\n",
    "      - If class file exists: merges ADC->class (left join on RoiNumber) so zero ROIs are preserved\n",
    "        and fills missing class values with 0.\n",
    "\n",
    "    Returns:\n",
    "        out_df: merged (adc + class if available) OR adc-only table\n",
    "        adc_df: full ADC dataframe with derived columns\n",
    "        class_df: loaded class dataframe if available else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # --- NEW: IsZeroRoi flag (computed before any dropping) ---\n",
    "    roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "    if all(c in adc_df.columns for c in roi_cols):\n",
    "        for c in roi_cols:\n",
    "            adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "        adc_df[\"IsZeroRoi\"] = (\n",
    "            (adc_df[\"RoiX\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiY\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiHeight\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiWidth\"].fillna(0) == 0)\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        adc_df[\"IsZeroRoi\"] = 0\n",
    "\n",
    "    # ---- drop early false trigger(s) BEFORE drop_zero_roi ----\n",
    "    if drop_false_trigger:\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df[\"IsZeroRoi\"] == 1)\n",
    "            )\n",
    "\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]  # preserve RoiNumber; don't reset index\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi and \"IsZeroRoi\" in adc_df.columns:\n",
    "        adc_df = adc_df.loc[adc_df[\"IsZeroRoi\"] == 0]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (with special first-row rule after filtering)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # first remaining row: InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0.0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber', 'ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed', 'IsZeroRoi']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge (ADC-driven to preserve zero ROIs)\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        # ADC -> class (left) keeps all ADC rows, including zero ROIs\n",
    "        merged_df = adc_out.merge(class_df, on='RoiNumber', how='left')\n",
    "\n",
    "        # Fill missing class values with 0 (e.g., zero ROIs)\n",
    "        class_cols = [c for c in class_df.columns if c not in ['pid', 'RoiNumber']]\n",
    "        if class_cols:\n",
    "            merged_df[class_cols] = merged_df[class_cols].fillna(0)\n",
    "\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b6103a23-0b12-44b0-abb8-9038047ab28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25,\n",
    "    use_class_files: bool = True,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "        class_path = class_map.get(prefix) if use_class_files else None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s,\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # ---- minimal (optional) naming clarity ----\n",
    "        if class_df is not None:\n",
    "            if drop_zero_roi:\n",
    "                outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "            else:\n",
    "                outfile = save_dir / f\"{prefix}_merged_keepzero.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4414ac72-cd6e-4473-a4c4-2c6b5b2d0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/spawn/All/spawn/\"\n",
    "merged_dir = \"../../IFCBData/spawn/All/spawn/zeroRoiMerge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1acb2e44-fdae-4a27-9cbf-6d07af2e57d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240501T181138_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240501T181138_IFCB145_adc_only.csv\n",
      "Processing D20240501T182329_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240501T182329_IFCB145_adc_only.csv\n",
      "Processing D20240501T185545_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240501T185545_IFCB145_adc_only.csv\n",
      "Processing D20240501T200201_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240501T200201_IFCB145_adc_only.csv\n",
      "Processing D20240501T204013_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240501T204013_IFCB145_adc_only.csv\n",
      "Processing D20240505T224724_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240505T224724_IFCB145_adc_only.csv\n",
      "Processing D20240505T230949_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240505T230949_IFCB145_adc_only.csv\n",
      "Processing D20240505T233338_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240505T233338_IFCB145_adc_only.csv\n",
      "Processing D20240507T173346_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T173346_IFCB145_adc_only.csv\n",
      "Processing D20240507T175731_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T175731_IFCB145_adc_only.csv\n",
      "Processing D20240507T182116_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T182116_IFCB145_adc_only.csv\n",
      "Processing D20240507T184622_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T184622_IFCB145_adc_only.csv\n",
      "Processing D20240507T185348_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T185348_IFCB145_adc_only.csv\n",
      "Processing D20240507T190144_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T190144_IFCB145_adc_only.csv\n",
      "Processing D20240507T191000_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T191000_IFCB145_adc_only.csv\n",
      "Processing D20240507T192151_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T192151_IFCB145_adc_only.csv\n",
      "Processing D20240507T192956_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T192956_IFCB145_adc_only.csv\n",
      "Processing D20240507T193742_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T193742_IFCB145_adc_only.csv\n",
      "Processing D20240507T200128_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T200128_IFCB145_adc_only.csv\n",
      "Processing D20240507T205306_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T205306_IFCB145_adc_only.csv\n",
      "Processing D20240507T211652_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240507T211652_IFCB145_adc_only.csv\n",
      "Processing D20240508T215317_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240508T215317_IFCB145_adc_only.csv\n",
      "Processing D20240508T221703_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240508T221703_IFCB145_adc_only.csv\n",
      "Processing D20240509T130156_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240509T130156_IFCB145_adc_only.csv\n",
      "Processing D20240509T132541_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240509T132541_IFCB145_adc_only.csv\n",
      "Processing D20240509T134927_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240509T134927_IFCB145_adc_only.csv\n",
      "Processing D20240513T135642_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T135642_IFCB145_adc_only.csv\n",
      "Processing D20240513T142027_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T142027_IFCB145_adc_only.csv\n",
      "Processing D20240513T144413_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T144413_IFCB145_adc_only.csv\n",
      "Processing D20240513T150800_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T150800_IFCB145_adc_only.csv\n",
      "Processing D20240513T153725_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T153725_IFCB145_adc_only.csv\n",
      "Processing D20240513T160111_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T160111_IFCB145_adc_only.csv\n",
      "Processing D20240513T162458_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T162458_IFCB145_adc_only.csv\n",
      "Processing D20240513T170117_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T170117_IFCB145_adc_only.csv\n",
      "Processing D20240513T172503_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T172503_IFCB145_adc_only.csv\n",
      "Processing D20240513T174850_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T174850_IFCB145_adc_only.csv\n",
      "Processing D20240513T181407_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T181407_IFCB145_adc_only.csv\n",
      "Processing D20240513T183753_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T183753_IFCB145_adc_only.csv\n",
      "Processing D20240513T190140_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240513T190140_IFCB145_adc_only.csv\n",
      "Processing D20240515T160214_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T160214_IFCB145_adc_only.csv\n",
      "Processing D20240515T162559_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T162559_IFCB145_adc_only.csv\n",
      "Processing D20240515T164946_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T164946_IFCB145_adc_only.csv\n",
      "Processing D20240515T171401_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T171401_IFCB145_adc_only.csv\n",
      "Processing D20240515T173747_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T173747_IFCB145_adc_only.csv\n",
      "Processing D20240515T180133_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T180133_IFCB145_adc_only.csv\n",
      "Processing D20240515T190009_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T190009_IFCB145_adc_only.csv\n",
      "Processing D20240515T194330_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T194330_IFCB145_adc_only.csv\n",
      "Processing D20240515T202005_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T202005_IFCB145_adc_only.csv\n",
      "Processing D20240515T204353_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240515T204353_IFCB145_adc_only.csv\n",
      "Processing D20240517T180112_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240517T180112_IFCB145_adc_only.csv\n",
      "Processing D20240517T201121_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240517T201121_IFCB145_adc_only.csv\n",
      "Processing D20240517T203508_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240517T203508_IFCB145_adc_only.csv\n",
      "Processing D20240517T205856_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240517T205856_IFCB145_adc_only.csv\n",
      "Processing D20240518T155749_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240518T155749_IFCB145_adc_only.csv\n",
      "Processing D20240518T162134_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240518T162134_IFCB145_adc_only.csv\n",
      "Processing D20240518T164519_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240518T164519_IFCB145_adc_only.csv\n",
      "Processing D20240521T162440_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T162440_IFCB145_adc_only.csv\n",
      "Processing D20240521T164826_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T164826_IFCB145_adc_only.csv\n",
      "Processing D20240521T171212_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T171212_IFCB145_adc_only.csv\n",
      "Processing D20240521T183034_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T183034_IFCB145_adc_only.csv\n",
      "Processing D20240521T185420_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T185420_IFCB145_adc_only.csv\n",
      "Processing D20240521T191805_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/All/spawn/zeroRoiMerge/D20240521T191805_IFCB145_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                    use_class_files=True,\n",
    "                                    class_suffixes=\"_class_scores.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d2affaa1-4c3f-4d0b-b360-9556593a86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test if it worked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "13b47e7d-8978-44d6-85e5-85fbf5a64592",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T015457_IFCB124_merged_keepzero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "69167a74-4bdd-476e-9304-4561ce7fd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "count_zeroroi = (testdf['IsZeroRoi'] == 1).sum()\n",
    "print(count_zeroroi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e007cc72-fc0a-49a9-8470-00217bdefbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoiNumber</th>\n",
       "      <th>ADCtime</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>InhibitTime</th>\n",
       "      <th>InhibitTimeDiff</th>\n",
       "      <th>VolumeAnalyzed</th>\n",
       "      <th>IsZeroRoi</th>\n",
       "      <th>RoiHeight</th>\n",
       "      <th>RoiWidth</th>\n",
       "      <th>RoiX</th>\n",
       "      <th>...</th>\n",
       "      <th>detritus_transparent</th>\n",
       "      <th>fecal_pellet</th>\n",
       "      <th>fiber</th>\n",
       "      <th>fiber_TAG_external_detritus</th>\n",
       "      <th>flagellate</th>\n",
       "      <th>flagellate_morphotype1</th>\n",
       "      <th>flagellate_morphotype3</th>\n",
       "      <th>pennate</th>\n",
       "      <th>pollen_spikey_dino</th>\n",
       "      <th>unknown2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1773</td>\n",
       "      <td>273.420911</td>\n",
       "      <td>273.448819</td>\n",
       "      <td>134.221762</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>0.580113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2064</td>\n",
       "      <td>314.422395</td>\n",
       "      <td>314.452778</td>\n",
       "      <td>155.250278</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>0.663344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2637</td>\n",
       "      <td>398.606909</td>\n",
       "      <td>398.640660</td>\n",
       "      <td>198.035677</td>\n",
       "      <td>0.083194</td>\n",
       "      <td>0.835854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>3501</td>\n",
       "      <td>531.341601</td>\n",
       "      <td>531.378160</td>\n",
       "      <td>260.560486</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>1.128407</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>5148</td>\n",
       "      <td>828.448915</td>\n",
       "      <td>828.492431</td>\n",
       "      <td>382.312083</td>\n",
       "      <td>0.080035</td>\n",
       "      <td>1.859085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>5248</td>\n",
       "      <td>848.417057</td>\n",
       "      <td>848.462222</td>\n",
       "      <td>389.823438</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>1.910995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6152</td>\n",
       "      <td>1032.057568</td>\n",
       "      <td>1032.107639</td>\n",
       "      <td>456.003854</td>\n",
       "      <td>0.081910</td>\n",
       "      <td>2.400432</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>6811</td>\n",
       "      <td>1179.716452</td>\n",
       "      <td>1179.770278</td>\n",
       "      <td>504.745069</td>\n",
       "      <td>0.082049</td>\n",
       "      <td>2.812605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
       "1772       1773   273.420911   273.448819   134.221762         0.079783   \n",
       "2063       2064   314.422395   314.452778   155.250278         0.081701   \n",
       "2636       2637   398.606909   398.640660   198.035677         0.083194   \n",
       "3500       3501   531.341601   531.378160   260.560486         0.081875   \n",
       "5147       5148   828.448915   828.492431   382.312083         0.080035   \n",
       "5247       5248   848.417057   848.462222   389.823438         0.081701   \n",
       "6151       6152  1032.057568  1032.107639   456.003854         0.081910   \n",
       "6810       6811  1179.716452  1179.770278   504.745069         0.082049   \n",
       "\n",
       "      VolumeAnalyzed  IsZeroRoi  RoiHeight  RoiWidth  RoiX  ...  \\\n",
       "1772        0.580113          1          0         0     0  ...   \n",
       "2063        0.663344          1          0         0     0  ...   \n",
       "2636        0.835854          1          0         0     0  ...   \n",
       "3500        1.128407          1          0         0     0  ...   \n",
       "5147        1.859085          1          0         0     0  ...   \n",
       "5247        1.910995          1          0         0     0  ...   \n",
       "6151        2.400432          1          0         0     0  ...   \n",
       "6810        2.812605          1          0         0     0  ...   \n",
       "\n",
       "      detritus_transparent fecal_pellet  fiber  fiber_TAG_external_detritus  \\\n",
       "1772                   0.0          0.0    0.0                          0.0   \n",
       "2063                   0.0          0.0    0.0                          0.0   \n",
       "2636                   0.0          0.0    0.0                          0.0   \n",
       "3500                   0.0          0.0    0.0                          0.0   \n",
       "5147                   0.0          0.0    0.0                          0.0   \n",
       "5247                   0.0          0.0    0.0                          0.0   \n",
       "6151                   0.0          0.0    0.0                          0.0   \n",
       "6810                   0.0          0.0    0.0                          0.0   \n",
       "\n",
       "      flagellate  flagellate_morphotype1  flagellate_morphotype3  pennate  \\\n",
       "1772         0.0                     0.0                     0.0      0.0   \n",
       "2063         0.0                     0.0                     0.0      0.0   \n",
       "2636         0.0                     0.0                     0.0      0.0   \n",
       "3500         0.0                     0.0                     0.0      0.0   \n",
       "5147         0.0                     0.0                     0.0      0.0   \n",
       "5247         0.0                     0.0                     0.0      0.0   \n",
       "6151         0.0                     0.0                     0.0      0.0   \n",
       "6810         0.0                     0.0                     0.0      0.0   \n",
       "\n",
       "      pollen_spikey_dino  unknown2  \n",
       "1772                 0.0       0.0  \n",
       "2063                 0.0       0.0  \n",
       "2636                 0.0       0.0  \n",
       "3500                 0.0       0.0  \n",
       "5147                 0.0       0.0  \n",
       "5247                 0.0       0.0  \n",
       "6151                 0.0       0.0  \n",
       "6810                 0.0       0.0  \n",
       "\n",
       "[8 rows x 148 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.loc[testdf[\"IsZeroRoi\"] == 1].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1dc593-c870-407a-9baf-ea33183a7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "testadc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
