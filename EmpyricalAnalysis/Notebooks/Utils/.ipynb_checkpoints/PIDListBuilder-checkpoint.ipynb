{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0217bd35-1077-4c40-93c5-0cb2f020cdc7",
   "metadata": {},
   "source": [
    "# Creating ways to genberate and filter PID lists from dashboard API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec80a9-dc20-4ff5-824a-79c1fcb6738d",
   "metadata": {},
   "source": [
    "## generates a list of all pids between two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca8bc24-1c3e-4368-b1dc-55733ba0fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "def get_ifcb_bins_datetime_filtered(base_url: str,\n",
    "                                    dataset: str,\n",
    "                                    start: str,\n",
    "                                    end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get all bins for a dataset from /api/list_bins, then filter by sample_time\n",
    "    between 'start' and 'end' (inclusive).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_url : e.g. \"https://habon-ifcb.whoi.edu\"\n",
    "    dataset  : e.g. \"nauset\"\n",
    "    start, end : ISO-like datetime strings, e.g. \"2025-06-25T09:00:00Z\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with only bins in the requested time window.\n",
    "    \"\"\"\n",
    "    base_url = base_url.rstrip(\"/\")\n",
    "    url = f\"{base_url}/api/list_bins?dataset={dataset}\"\n",
    "\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Adjust this column name if needed, but on HABON it should be 'sample_time'\n",
    "    df['sample_time'] = pd.to_datetime(df[\"sample_time\"])\n",
    "\n",
    "    start_dt = pd.to_datetime(start)\n",
    "    end_dt   = pd.to_datetime(end)\n",
    "\n",
    "    mask = (df[\"sample_time\"] >= start_dt) & (df[\"sample_time\"] <= end_dt)\n",
    "    return df.loc[mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131f32-3782-4261-bb1e-d1bd675fc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example usage ##\n",
    "\n",
    "###URL OPTIONS\n",
    "## PERCY: http://percy.whoi.edu:8000\n",
    "## HABON: https://habon-ifcb.whoi.edu\n",
    "\n",
    "base_url = \"https://habon-ifcb.whoi.edu\"\n",
    "dataset = \"hablab_beadsExp\"\n",
    "\n",
    "start_dt = \"2026-02-03T00:00:00Z\"\n",
    "end_dt   = \"2026-02-26T12:00:00Z\"\n",
    "\n",
    "\n",
    "bins_df = get_ifcb_bins_datetime_filtered(base_url, dataset, start_dt, end_dt)\n",
    "bins = bins_df[\"pid\"].tolist()\n",
    "\n",
    "print(f\"Found {len(bins)} bins between {start_dt} and {end_dt}\")\n",
    "print(bins[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08d7c8-c631-42fd-b3ec-072e28ea3302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7630f-519f-498b-b75f-6482748cef67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5774ec-b7d2-4999-9a11-7d9e955bb9c3",
   "metadata": {},
   "source": [
    "# Pick PIDS near times across date range. Let's pick just a few per day over longer timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "718e4f88-8549-4687-ac84-edea4e751615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def get_ifcb_pids_by_daily_times(\n",
    "    base_url: str,\n",
    "    dataset: str,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    times: List[str],\n",
    "    *,\n",
    "    same_day_only: bool = True,\n",
    ") -> Tuple[List[str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each day in [start, end], and for each time in `times` (HH:MM or HH:MM:SS),\n",
    "    find the first bin with sample_time >= that target time.\n",
    "    \n",
    "    If same_day_only=True, matches that roll into the next day are dropped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pids: list of selected pid strings (unique, in chronological order)\n",
    "    picked_df: dataframe with target_time, sample_time, pid, and delta\n",
    "    \"\"\"\n",
    "    base_url = base_url.rstrip(\"/\")\n",
    "    url = f\"{base_url}/api/list_bins?dataset={dataset}\"\n",
    "\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if \"sample_time\" not in df.columns or \"pid\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'sample_time' and 'pid' columns from /api/list_bins response.\")\n",
    "\n",
    "    # Parse times\n",
    "    df[\"sample_time\"] = pd.to_datetime(df[\"sample_time\"], utc=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"sample_time\"]).sort_values(\"sample_time\")\n",
    "\n",
    "    start_dt = pd.to_datetime(start, utc=True)\n",
    "    end_dt   = pd.to_datetime(end,   utc=True)\n",
    "\n",
    "    # Filter bins to time window (inclusive)\n",
    "    df = df[(df[\"sample_time\"] >= start_dt) & (df[\"sample_time\"] <= end_dt)].copy()\n",
    "    if df.empty:\n",
    "        return [], pd.DataFrame(columns=[\"target_time\", \"sample_time\", \"pid\", \"delta\"])\n",
    "\n",
    "    # Build target schedule: every day x each desired time\n",
    "    days = pd.date_range(start=start_dt.normalize(), end=end_dt.normalize(), freq=\"D\", tz=\"UTC\")\n",
    "    # Convert \"HH:MM[:SS]\" strings to timedeltas\n",
    "    tds = []\n",
    "    for t in times:\n",
    "        parts = t.split(\":\")\n",
    "        if len(parts) == 2:\n",
    "            hh, mm = parts\n",
    "            ss = \"0\"\n",
    "        elif len(parts) == 3:\n",
    "            hh, mm, ss = parts\n",
    "        else:\n",
    "            raise ValueError(f\"Time '{t}' must be 'HH:MM' or 'HH:MM:SS'\")\n",
    "        tds.append(pd.to_timedelta(f\"{int(hh):02d}:{int(mm):02d}:{int(ss):02d}\"))\n",
    "\n",
    "    targets = pd.DataFrame({\n",
    "        \"target_time\": [d + td for d in days for td in tds]\n",
    "    }).sort_values(\"target_time\")\n",
    "\n",
    "    # Keep only targets that fall within the overall start/end window\n",
    "    targets = targets[(targets[\"target_time\"] >= start_dt) & (targets[\"target_time\"] <= end_dt)].copy()\n",
    "    if targets.empty:\n",
    "        return [], pd.DataFrame(columns=[\"target_time\", \"sample_time\", \"pid\", \"delta\"])\n",
    "\n",
    "    # Forward \"asof\" join: for each target_time, find first sample_time >= target_time\n",
    "    bins_for_asof = df[[\"sample_time\", \"pid\"]].rename(columns={\"sample_time\": \"sample_time_match\"})\n",
    "    bins_for_asof = bins_for_asof.sort_values(\"sample_time_match\")\n",
    "\n",
    "    picked = pd.merge_asof(\n",
    "        targets.sort_values(\"target_time\"),\n",
    "        bins_for_asof,\n",
    "        left_on=\"target_time\",\n",
    "        right_on=\"sample_time_match\",\n",
    "        direction=\"forward\",\n",
    "        allow_exact_matches=True,\n",
    "    )\n",
    "\n",
    "    picked = picked.rename(columns={\"sample_time_match\": \"sample_time\"})\n",
    "    picked = picked.dropna(subset=[\"sample_time\", \"pid\"]).copy()\n",
    "\n",
    "    # Optionally enforce same-day matches\n",
    "    if same_day_only:\n",
    "        picked = picked[picked[\"sample_time\"].dt.normalize() == picked[\"target_time\"].dt.normalize()].copy()\n",
    "\n",
    "    picked[\"delta\"] = picked[\"sample_time\"] - picked[\"target_time\"]\n",
    "\n",
    "    # Optional: de-duplicate if two targets land on the same PID (happens if bins are sparse)\n",
    "    picked = picked.sort_values(\"target_time\")\n",
    "    picked_unique = picked.drop_duplicates(subset=[\"pid\"], keep=\"first\").copy()\n",
    "\n",
    "    pids = picked_unique[\"pid\"].tolist()\n",
    "    return pids, picked_unique[[\"target_time\", \"sample_time\", \"pid\", \"delta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ee2fbc1-22d2-4b28-b55b-73c9b8bf4949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D20250907T021646_IFCB127', 'D20250907T081448_IFCB127', 'D20250907T141247_IFCB127', 'D20250907T201554_IFCB127', 'D20250908T021352_IFCB127', 'D20250908T081151_IFCB127', 'D20250908T140951_IFCB127', 'D20250908T201258_IFCB127', 'D20250909T021058_IFCB127', 'D20250909T080857_IFCB127']\n",
      "                target_time               sample_time  \\\n",
      "0 2025-09-07 02:00:00+00:00 2025-09-07 02:16:46+00:00   \n",
      "1 2025-09-07 08:00:00+00:00 2025-09-07 08:14:48+00:00   \n",
      "2 2025-09-07 14:00:00+00:00 2025-09-07 14:12:47+00:00   \n",
      "3 2025-09-07 20:00:00+00:00 2025-09-07 20:15:54+00:00   \n",
      "4 2025-09-08 02:00:00+00:00 2025-09-08 02:13:52+00:00   \n",
      "5 2025-09-08 08:00:00+00:00 2025-09-08 08:11:51+00:00   \n",
      "6 2025-09-08 14:00:00+00:00 2025-09-08 14:09:51+00:00   \n",
      "7 2025-09-08 20:00:00+00:00 2025-09-08 20:12:58+00:00   \n",
      "8 2025-09-09 02:00:00+00:00 2025-09-09 02:10:58+00:00   \n",
      "9 2025-09-09 08:00:00+00:00 2025-09-09 08:08:57+00:00   \n",
      "\n",
      "                        pid           delta  \n",
      "0  D20250907T021646_IFCB127 0 days 00:16:46  \n",
      "1  D20250907T081448_IFCB127 0 days 00:14:48  \n",
      "2  D20250907T141247_IFCB127 0 days 00:12:47  \n",
      "3  D20250907T201554_IFCB127 0 days 00:15:54  \n",
      "4  D20250908T021352_IFCB127 0 days 00:13:52  \n",
      "5  D20250908T081151_IFCB127 0 days 00:11:51  \n",
      "6  D20250908T140951_IFCB127 0 days 00:09:51  \n",
      "7  D20250908T201258_IFCB127 0 days 00:12:58  \n",
      "8  D20250909T021058_IFCB127 0 days 00:10:58  \n",
      "9  D20250909T080857_IFCB127 0 days 00:08:57  \n"
     ]
    }
   ],
   "source": [
    "### Example Usage ###\n",
    "pids, picked_df = get_ifcb_pids_by_daily_times(\n",
    "    base_url=\"https://habon-ifcb.whoi.edu\",\n",
    "    dataset=\"mvco\",\n",
    "    start=\"2025-09-07T00:00:00Z\",\n",
    "    end=\"2025-10-26T23:59:59Z\",\n",
    "    times=[\"02:00\", \"08:00\", \"14:00\", \"20:00\"],   # pick ~4 per day\n",
    "    same_day_only=True\n",
    ")\n",
    "\n",
    "print(pids[:10])\n",
    "print(picked_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c51fa21-00c1-4c81-b6bb-296fdba341c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To save pidlist as json file \n",
    "import json\n",
    "with open(\"../../IFCBData/PIDLists/mvcoTest.json\", \"w\") as f:\n",
    "    json.dump(pids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ac162-11d6-4791-9e40-feb6e0e59a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8158b5-9faf-4c61-9bba-0f0af31e1708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
