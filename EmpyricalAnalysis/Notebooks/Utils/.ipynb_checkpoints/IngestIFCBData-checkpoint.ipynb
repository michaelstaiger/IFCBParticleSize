{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d65a6a-c6be-4af4-bc2a-ed1398746712",
   "metadata": {},
   "source": [
    "### Ingests a single set of ADC, HDR and Class files \n",
    "\n",
    "Takes the required info from each file and creates single merged file \n",
    "Logic\n",
    "1) Parse ADCFileFormat from .hdr to get column names\n",
    "2) Load .adc with those headers\n",
    "3) Add RoiNumber to ADC as 1 - N\n",
    "4) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 -- this removes zero roi triggers so we can merge with class file on roi number\n",
    "5) Add InhibitTimeDiff = diff(InhibitTime).fillna(0) -- useful for understanding sample density\n",
    "6) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240  -- needed for concentration estimates and also useful for understanding sample density\n",
    "7) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23) -- used to merge with adc file\n",
    "8) Merge class_df with ADC-derived columns on RoiNumber\n",
    "9) Return merged_df (and adc_df, class_df)\n",
    "\n",
    "This gives you dataset of all rois with class scores and associated ADC metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2145f1b4-301d-4bb1-a7e3-88bd86c4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: str,\n",
    "                drop_zero_roi: bool = True):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Parse ADCFileFormat from .hdr to get column names\n",
    "      2) Load .adc with those headers\n",
    "      3) Add RoiNumber to ADC as 1..N\n",
    "      4) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 (optionally)\n",
    "      5) Add InhibitTimeDiff = diff(InhibitTime).fillna(0)\n",
    "      6) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240\n",
    "      7) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23)\n",
    "      8) Merge class_df with ADC-derived columns on RoiNumber\n",
    "      9) Return merged_df (and adc_df, class_df)\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path)\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(\"ADCFileFormat not found in header file.\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        # ensure numeric in case strings slipped in\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff().fillna(0)\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # 7) Load class CSV + extract RoiNumber from pid\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    if 'pid' not in class_df.columns:\n",
    "        raise ValueError(\"Expected 'pid' column in class CSV to extract RoiNumber.\")\n",
    "    class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # 8) Merge on RoiNumber\n",
    "    cols_to_keep = ['RoiNumber', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    merged_df = class_df.merge(adc_df[cols_to_keep], on='RoiNumber', how='left')\n",
    "\n",
    "    # 9) Return\n",
    "    return merged_df, adc_df, class_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cec2d-252f-4a06-bbe4-9f8bfeeb1c68",
   "metadata": {},
   "source": [
    "## Loops over a directory and outputs a merged directory\n",
    "\n",
    "wrapper for the ingest_ifcb function that merges based on the initial string of the file names and writes out merged datasets to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e1e6a4-5051-4f72-9927-bc3ebb4a6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "def ingest_ifcb_directory(directory: str,\n",
    "                          drop_zero_roi: bool = True,\n",
    "                          save_path: str | None = None) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loop over a directory, find sets of .adc, .hdr, and class CSV files\n",
    "    that share the same IFCB run prefix, and return merged dataframes.\n",
    "\n",
    "    Args:\n",
    "        directory: Folder containing IFCB .adc, .hdr, and class CSV files.\n",
    "        drop_zero_roi: Passed to ingest_ifcb().\n",
    "        save_path: Optional folder to save merged CSVs.\n",
    "                   If None, files are saved in the source directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: { prefix : merged_dataframe }\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_files = list(directory.glob(\"*.adc\"))\n",
    "    hdr_files = list(directory.glob(\"*.hdr\"))\n",
    "    class_files = list(directory.glob(\"*class*.csv\"))\n",
    "\n",
    "    # Build file lookup maps\n",
    "    adc_map   = {f.stem: f for f in adc_files}\n",
    "    hdr_map   = {f.stem: f for f in hdr_files}\n",
    "    class_map = {f.stem.replace(\"_class_vNone\", \"\").replace(\"_class\", \"\"): f\n",
    "                 for f in class_files}\n",
    "\n",
    "    prefixes = set(adc_map.keys()) | set(hdr_map.keys()) | set(class_map.keys())\n",
    "\n",
    "    merged_results = {}\n",
    "\n",
    "    for prefix in sorted(prefixes):\n",
    "        adc_path   = adc_map.get(prefix)\n",
    "        hdr_path   = hdr_map.get(prefix)\n",
    "        class_path = class_map.get(prefix)\n",
    "\n",
    "        # Require complete sets\n",
    "        if not (adc_path and hdr_path and class_path):\n",
    "            print(f\"Skipping {prefix}: incomplete set of files.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        merged_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=adc_path,\n",
    "            hdr_path=hdr_path,\n",
    "            class_csv_path=class_path,\n",
    "            drop_zero_roi=drop_zero_roi\n",
    "        )\n",
    "\n",
    "        merged_results[prefix] = merged_df\n",
    "\n",
    "        # Save output to designated location\n",
    "        outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        merged_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved merged file → {outfile}\")\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59245ed6-33e8-4e76-ab1f-556d1e8bfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac68709-f90c-4e6a-849f-9d5756356e6f",
   "metadata": {},
   "source": [
    "## Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942fa757-72b7-4da7-aad0-a9467d78e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/CosmicData/\"\n",
    "merged_dir = \"../../IFCBData/CosmicData/mergedData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "061e8152-ae41-4838-8fb0-ab83dcbe3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20250827T182211_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T182211_IFCB144_merged.csv\n",
      "Processing D20250827T184541_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T184541_IFCB144_merged.csv\n",
      "Processing D20250827T190910_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T190910_IFCB144_merged.csv\n",
      "Processing D20250827T193241_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T193241_IFCB144_merged.csv\n",
      "Processing D20250827T195610_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T195610_IFCB144_merged.csv\n",
      "Processing D20250827T201941_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T201941_IFCB144_merged.csv\n",
      "Processing D20250827T204310_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T204310_IFCB144_merged.csv\n",
      "Processing D20250827T210640_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T210640_IFCB144_merged.csv\n",
      "Skipping D20250827T213010_IFCB144: incomplete set of files.\n",
      "Processing D20250827T215339_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T215339_IFCB144_merged.csv\n",
      "Processing D20250827T221803_IFCB144...\n",
      "Saved merged file → ../../IFCBData/CosmicData/mergedData/D20250827T221803_IFCB144_merged.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7429804-cf96-4e37-9896-4b4f702fa89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1436e46e-5127-488a-b2fe-0ff0bb763dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv( \"../../IFCBData/CosmicData/mergedData/D20250827T182211_IFCB144_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38c7e0db-e7c0-49d4-9a66-ce3b8f534a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                  pid    Acantharia  Acanthoica_quattrospina  \\\n",
      "0     D20250827T182211_IFCB144_00002  1.000000e-07             1.675000e-04   \n",
      "1     D20250827T182211_IFCB144_00003  6.000000e-08             0.000000e+00   \n",
      "2     D20250827T182211_IFCB144_00004  0.000000e+00             0.000000e+00   \n",
      "3     D20250827T182211_IFCB144_00005  0.000000e+00             0.000000e+00   \n",
      "4     D20250827T182211_IFCB144_00006  0.000000e+00             0.000000e+00   \n",
      "...                              ...           ...                      ...   \n",
      "5118  D20250827T182211_IFCB144_05208  0.000000e+00             5.400000e-07   \n",
      "5119  D20250827T182211_IFCB144_05209  0.000000e+00             9.660000e-06   \n",
      "5120  D20250827T182211_IFCB144_05210  0.000000e+00             2.754000e-03   \n",
      "5121  D20250827T182211_IFCB144_05211  0.000000e+00             0.000000e+00   \n",
      "5122  D20250827T182211_IFCB144_05212  1.000000e-07             2.736000e-05   \n",
      "\n",
      "          Akashiwo  Alexandrium_catenella  Alexandrium_catenella_TAG_doublet  \\\n",
      "0     6.600000e-07           1.970000e-06                       6.740000e-06   \n",
      "1     0.000000e+00           6.000000e-08                       5.400000e-07   \n",
      "2     0.000000e+00           0.000000e+00                       0.000000e+00   \n",
      "3     0.000000e+00           7.000000e-07                       6.000000e-08   \n",
      "4     0.000000e+00           1.000000e-07                       5.000000e-07   \n",
      "...            ...                    ...                                ...   \n",
      "5118  6.000000e-08           3.000000e-07                       1.000000e-06   \n",
      "5119  9.000000e-07           6.000000e-07                       4.050000e-06   \n",
      "5120  0.000000e+00           7.000000e-07                       2.400000e-07   \n",
      "5121  0.000000e+00           0.000000e+00                       0.000000e+00   \n",
      "5122  2.000000e-07           7.330000e-06                       5.200000e-06   \n",
      "\n",
      "            Amoeba   Amphidinium        Amylax  Apedinella  ...      unknown2  \\\n",
      "0     1.693000e-03  1.300000e-06  6.600000e-07    0.240100  ...  3.600000e-07   \n",
      "1     2.091000e-04  2.000000e-07  0.000000e+00    0.000159  ...  5.400000e-07   \n",
      "2     6.000000e-08  0.000000e+00  0.000000e+00    0.000000  ...  0.000000e+00   \n",
      "3     0.000000e+00  0.000000e+00  1.657000e-05    0.000000  ...  0.000000e+00   \n",
      "4     0.000000e+00  0.000000e+00  5.000000e-07    0.000000  ...  0.000000e+00   \n",
      "...            ...           ...           ...         ...  ...           ...   \n",
      "5118  1.036000e-01  1.000000e-06  2.000000e-07    0.029680  ...  2.400000e-07   \n",
      "5119  9.600000e-05  6.000000e-08  0.000000e+00    0.970000  ...  0.000000e+00   \n",
      "5120  9.894000e-05  3.600000e-07  0.000000e+00    0.023100  ...  1.000000e-07   \n",
      "5121  2.070000e-04  0.000000e+00  0.000000e+00    0.000023  ...  0.000000e+00   \n",
      "5122  2.120000e-03  4.000000e-07  0.000000e+00    0.216400  ...  1.500000e-06   \n",
      "\n",
      "      RoiNumber      RunTime  InhibitTime  InhibitTimeDiff  VolumeAnalyzed  \\\n",
      "0             2     5.359091     0.069368         0.000000        0.022041   \n",
      "1             3     5.487339     0.152155         0.082786        0.022230   \n",
      "2             4     5.808566     0.235530         0.083375        0.023221   \n",
      "3             5     5.895723     0.318952         0.083422        0.023237   \n",
      "4             6     6.085354     0.477535         0.158583        0.023366   \n",
      "...         ...          ...          ...              ...             ...   \n",
      "5118       5208  1200.027083   452.710347         0.083264        3.113820   \n",
      "5119       5209  1200.507778   452.792326         0.081979        3.115481   \n",
      "5120       5210  1200.918194   452.874896         0.082569        3.116847   \n",
      "5121       5211  1201.173056   452.956563         0.081667        3.117569   \n",
      "5122       5212  1201.371944   453.037951         0.081389        3.118058   \n",
      "\n",
      "      RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0            60        80   996   422  \n",
      "1            76        88   988   422  \n",
      "2            52        72   996   582  \n",
      "3           100       112   940   870  \n",
      "4            92       120   932   846  \n",
      "...         ...       ...   ...   ...  \n",
      "5118         60        88   972   614  \n",
      "5119         60        88   956   910  \n",
      "5120         60        80   964   734  \n",
      "5121         60        72   996   654  \n",
      "5122         52        72   988   646  \n",
      "\n",
      "[5123 rows x 152 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27d467-606f-46f2-9d9d-6d6a518fc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
