{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingests a single set of ADC, HDR and Class files \n",
    "\n",
    "Takes the required info from each file and creates single merged file \n",
    "Logic Updated to version 3  to contain new logic, class flexibility, and zero roi options\n",
    "1) Parse ADCFileFormat from .hdr to get column names\n",
    "2) Load .adc with those headers\n",
    "3) Add RoiNumber to ADC as 1 - N\n",
    "4) apply false trigger filterring\n",
    "5) Tag all rois with RoiX=RoiY=RoiHeight=RoiWidth=0  as IsZeroRoi = 1,  Optionally:  Remove these rows if only care about class \n",
    "6) Add InhibitTimeDiff = diff(InhibitTime).fillna(0) -- useful for understanding sample density\n",
    "7) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240  -- needed for concentration estimates and also useful for understanding sample density\n",
    "8) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23) -- used to merge with adc file - left merged on ADC File\n",
    "9) Merge class_df with ADC-derived columns on RoiNumber - for zero rois fill all class scores with 0s\n",
    "10) Return merged_df (and adc_df, class_df)\n",
    "\n",
    "This gives you dataset of all rois with class scores and associated ADC metadata\n",
    "\n",
    " NOTE: Has been updated use the  version that is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currentlly recomend using Versoion 3 at the bottom for most flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Version 1 Dont use this !\n",
    "saved for future incase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: str,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Parse ADCFileFormat from .hdr to get column names\n",
    "      2) Load .adc with those headers\n",
    "      3) Add RoiNumber to ADC as 1..N\n",
    "      4) (NEW) Drop false trigger if present: RunTime < 0.25 AND zero ROI\n",
    "      5) Remove rows with RoiX=RoiY=RoiHeight=RoiWidth=0 (optionally)\n",
    "      6) Add InhibitTimeDiff with special first-row rule\n",
    "      7) Add VolumeAnalyzed = (RunTime - InhibitTime) / 240\n",
    "      8) Load class CSV and extract RoiNumber from pid ('..._00023' -> 23)\n",
    "      9) Merge class_df with ADC-derived columns on RoiNumber\n",
    "      10) Return merged_df (and adc_df, class_df)\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path)\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(\"ADCFileFormat not found in header file.\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger if present (before any other filtering) ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            # Drop it if present; keep original RoiNumber values; don't reset index\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (first real trigger uses cumulative inhibit time)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # First remaining row (first real trigger): InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # Safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # 7) Load class CSV + extract RoiNumber from pid\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    if 'pid' not in class_df.columns:\n",
    "        raise ValueError(\"Expected 'pid' column in class CSV to extract RoiNumber.\")\n",
    "    class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # 8) Merge on RoiNumber\n",
    "    cols_to_keep = ['RoiNumber', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    merged_df = class_df.merge(adc_df[cols_to_keep], on='RoiNumber', how='left')\n",
    "\n",
    "    # 9) Return\n",
    "    return merged_df, adc_df, class_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops over a directory and outputs a merged directory\n",
    "\n",
    "wrapper for the ingest_ifcb function that merges based on the initial string of the file names and writes out merged datasets to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "import fnmatch\n",
    "\n",
    "def ingest_ifcb_directory(directory: str,\n",
    "                          drop_zero_roi: bool = True,\n",
    "                          save_path: str | None = None,\n",
    "                          # ---- NEW (optional) ----\n",
    "                          drop_false_trigger: bool = True,\n",
    "                          false_trigger_runtime_s: float = 0.25,\n",
    "                          class_suffixes: Optional[tuple] = None,\n",
    "                          prefer_newest_class_file: bool = True\n",
    "                          ) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loop over a directory, find sets of .adc, .hdr, and class CSV files\n",
    "    that share the same IFCB run prefix, and return merged dataframes.\n",
    "\n",
    "    Minimal changes:\n",
    "      - class file detection is now prefix-based and flexible (handles variable suffixes)\n",
    "      - passes drop_false_trigger + false_trigger_runtime_s into ingest_ifcb\n",
    "\n",
    "    Args:\n",
    "        directory: Folder containing IFCB .adc, .hdr, and class CSV files.\n",
    "        drop_zero_roi: Passed to ingest_ifcb().\n",
    "        save_path: Optional folder to save merged CSVs.\n",
    "        drop_false_trigger: If True, drop early false trigger(s) in ingest_ifcb.\n",
    "        false_trigger_runtime_s: Runtime cutoff for false trigger rule.\n",
    "        class_suffixes: Optional patterns/suffixes for class files.\n",
    "            - If None (default): accept any CSV that starts with prefix and contains 'class'\n",
    "            - If provided: may include exact suffixes or wildcard patterns, e.g. (\"_class*.csv\",)\n",
    "        prefer_newest_class_file: If multiple class files match, choose newest (True) or name-sorted (False).\n",
    "\n",
    "    Returns:\n",
    "        dict: { prefix : merged_dataframe }\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_files = list(directory.glob(\"*.adc\"))\n",
    "    hdr_files = list(directory.glob(\"*.hdr\"))\n",
    "    class_files = list(directory.glob(\"*class*.csv\"))\n",
    "\n",
    "    # Build file lookup maps\n",
    "    adc_map = {f.stem: f for f in adc_files}\n",
    "    hdr_map = {f.stem: f for f in hdr_files}\n",
    "\n",
    "    # Only consider prefixes that have adc+hdr (required)\n",
    "    prefixes = sorted(set(adc_map.keys()).intersection(set(hdr_map.keys())))\n",
    "\n",
    "    def _class_matches(prefix: str, filename: str) -> bool:\n",
    "        # Must start with the prefix (strong constraint)\n",
    "        if not filename.startswith(prefix):\n",
    "            return False\n",
    "\n",
    "        # If no suffix patterns provided, accept any \"class\" csv starting with prefix\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        # Otherwise allow exact suffixes OR wildcard patterns\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                # interpret token as a suffix pattern, e.g. \"_class*.csv\"\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                # interpret token as exact suffix\n",
    "                if filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class map by searching best match per prefix\n",
    "    class_map = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = [f for f in class_files if _class_matches(prefix, f.name)]\n",
    "        if matches:\n",
    "            best = max(matches, key=lambda x: x.stat().st_mtime) if prefer_newest_class_file else sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    merged_results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map.get(prefix)\n",
    "        hdr_path = hdr_map.get(prefix)\n",
    "        class_path = class_map.get(prefix)\n",
    "\n",
    "        # Require class file too (matches your original behavior)\n",
    "        if not class_path:\n",
    "            print(f\"Skipping {prefix}: missing class CSV.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        merged_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path),\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            # ---- pass-through new logic ----\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s\n",
    "        )\n",
    "\n",
    "        merged_results[prefix] = merged_df\n",
    "\n",
    "        # Save output to designated location\n",
    "        outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        merged_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved merged file â†’ {outfile}\")\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/AlexandriumTest/\"\n",
    "merged_dir = \"../../IFCBData/AlexandriumTest/newmerged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240501T200201_IFCB145 (class=no)...\n",
      "Saved: ../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../IFCBData/spawn/zygotes/merged/D20240501T200201_IFCB145_adc_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       RoiNumber      ADCtime      RunTime  InhibitTime  InhibitTimeDiff  \\\n",
      "0             2     4.931790     4.953893     0.083047         0.000000   \n",
      "1             3     5.104920     5.127059     0.166803         0.083757   \n",
      "2             4     5.774158     5.796293     0.249392         0.082589   \n",
      "3             5     5.865553     5.888199     0.333301         0.083908   \n",
      "4             6     5.952413     5.972958     0.414779         0.081478   \n",
      "...         ...          ...          ...          ...              ...   \n",
      "6378       6786  1198.809496  1198.831528   517.552604         0.083160   \n",
      "6379       6787  1199.135671  1199.157500   517.634792         0.082187   \n",
      "6380       6789  1199.493438  1199.514583   517.801215         0.166424   \n",
      "6381       6790  1200.150306  1200.174167   517.885764         0.084549   \n",
      "6382       6791  1200.525941  1200.548333   517.968507         0.082743   \n",
      "\n",
      "      VolumeAnalyzed  RoiHeight  RoiWidth  RoiX  RoiY  \n",
      "0           0.020295         44        88   948   534  \n",
      "1           0.020668        188       208   764   630  \n",
      "2           0.023112         84       104   892   782  \n",
      "3           0.023145        204       248   740   342  \n",
      "4           0.023159        204       240   748   398  \n",
      "...              ...        ...       ...   ...   ...  \n",
      "6378        2.838662         60        96   900   782  \n",
      "6379        2.839678         68        96   876   782  \n",
      "6380        2.840472         44        64   932   758  \n",
      "6381        2.842868         68       120   884   838  \n",
      "6382        2.844083         68       144   884   630  \n",
      "\n",
      "[6383 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Version2\n",
    "\n",
    "## Class file optional Versions -- same logic just now can handle missing class files \n",
    "## Allows for skipping first false trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(adc_path: str,\n",
    "                hdr_path: str,\n",
    "                class_csv_path: Optional[str] = None,\n",
    "                drop_zero_roi: bool = True,\n",
    "                # ---- NEW (optional) ----\n",
    "                drop_false_trigger: bool = True,\n",
    "                false_trigger_runtime_s: float = 0.25\n",
    "                ) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    NEW:\n",
    "      - drops early false trigger(s) if: RunTime < false_trigger_runtime_s AND (RoiX=RoiY=RoiHeight=RoiWidth=0)\n",
    "      - recomputes InhibitTimeDiff after dropping false triggers:\n",
    "            first row: InhibitTimeDiff = InhibitTime\n",
    "            later rows: InhibitTimeDiff = diff(InhibitTime)\n",
    "\n",
    "    Returns:\n",
    "        merged_df:\n",
    "            - if class provided & exists: class_df merged with adc-derived columns on RoiNumber\n",
    "            - else: adc-derived dataframe containing RoiNumber + derived columns (and ROI geometry if present)\n",
    "        adc_df: ADC dataframe with parsed headers + derived columns\n",
    "        class_df: class dataframe if loaded, else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # ---- NEW: drop early false trigger(s) BEFORE drop_zero_roi ----\n",
    "    if drop_false_trigger:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            # numeric coercion for robust comparisons\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "            for c in roi_cols:\n",
    "                adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df['RoiX'].fillna(0) == 0) &\n",
    "                (adc_df['RoiY'].fillna(0) == 0) &\n",
    "                (adc_df['RoiHeight'].fillna(0) == 0) &\n",
    "                (adc_df['RoiWidth'].fillna(0) == 0)\n",
    "            )\n",
    "\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]  # preserve RoiNumber, don't reset index\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi:\n",
    "        roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "        if all(col in adc_df.columns for col in roi_cols):\n",
    "            keep_mask = ~((adc_df['RoiX'] == 0) &\n",
    "                          (adc_df['RoiY'] == 0) &\n",
    "                          (adc_df['RoiHeight'] == 0) &\n",
    "                          (adc_df['RoiWidth'] == 0))\n",
    "            adc_df = adc_df.loc[keep_mask]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (with special first-row rule after filtering)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # first remaining row: InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0.0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber', 'ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        merged_df = class_df.merge(adc_out, on='RoiNumber', how='left')\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    "    # ---- existing options ----\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25,\n",
    "    # ---- NEW (minimal) ----\n",
    "    use_class_files: bool = True,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process a folder of IFCB files. For each prefix:\n",
    "      - requires .adc and .hdr\n",
    "      - class CSV is optional\n",
    "\n",
    "    NEW:\n",
    "      - if use_class_files=False, class CSVs are ignored even if present\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    # Only process prefixes that actually have adc+hdr\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    # Candidate class CSVs: anything with 'class' in the filename\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Build class_map keyed by prefix\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "\n",
    "        # ---- MINIMAL CHANGE: ignore class files if requested ----\n",
    "        class_path = class_map.get(prefix) if use_class_files else None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s,\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # Save with different suffix depending on whether class exists\n",
    "        if class_df is not None:\n",
    "            outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing that it works \n",
    "Build a directory of files you want to merge\n",
    "Create a directory to save the new merged files into \n",
    "run \n",
    "test that the files look the way they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/DenseAlex/nauset/\"\n",
    "merged_dir = \"../../IFCBData/DenseAlex/nauset/zeroRoiMerge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20240402T001855_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T001855_IFCB124_adc_only.csv\n",
      "Processing D20240402T004255_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T004255_IFCB124_adc_only.csv\n",
      "Processing D20240402T010656_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T010656_IFCB124_adc_only.csv\n",
      "Processing D20240402T013056_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T013056_IFCB124_adc_only.csv\n",
      "Processing D20240402T015457_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T015457_IFCB124_adc_only.csv\n",
      "Processing D20240402T021857_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T021857_IFCB124_adc_only.csv\n",
      "Processing D20240402T024258_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T024258_IFCB124_adc_only.csv\n",
      "Processing D20240402T030659_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T030659_IFCB124_adc_only.csv\n",
      "Processing D20240402T033059_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T033059_IFCB124_adc_only.csv\n",
      "Processing D20240402T035500_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T035500_IFCB124_adc_only.csv\n",
      "Processing D20240402T041916_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T041916_IFCB124_adc_only.csv\n",
      "Processing D20240402T044316_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T044316_IFCB124_adc_only.csv\n",
      "Processing D20240402T050717_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T050717_IFCB124_adc_only.csv\n",
      "Processing D20240402T053118_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T053118_IFCB124_adc_only.csv\n",
      "Processing D20240402T055518_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T055518_IFCB124_adc_only.csv\n",
      "Processing D20240402T061919_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T061919_IFCB124_adc_only.csv\n",
      "Processing D20240402T064320_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T064320_IFCB124_adc_only.csv\n",
      "Processing D20240402T070721_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T070721_IFCB124_adc_only.csv\n",
      "Processing D20240402T073122_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T073122_IFCB124_adc_only.csv\n",
      "Processing D20240402T075523_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T075523_IFCB124_adc_only.csv\n",
      "Processing D20240402T081924_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T081924_IFCB124_adc_only.csv\n",
      "Processing D20240402T084324_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T084324_IFCB124_adc_only.csv\n",
      "Processing D20240402T090725_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T090725_IFCB124_adc_only.csv\n",
      "Processing D20240402T093125_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T093125_IFCB124_adc_only.csv\n",
      "Processing D20240402T095526_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T095526_IFCB124_adc_only.csv\n",
      "Processing D20240402T101927_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T101927_IFCB124_adc_only.csv\n",
      "Processing D20240402T104327_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T104327_IFCB124_adc_only.csv\n",
      "Processing D20240402T110728_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T110728_IFCB124_adc_only.csv\n",
      "Processing D20240402T113128_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T113128_IFCB124_adc_only.csv\n",
      "Processing D20240402T115529_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T115529_IFCB124_adc_only.csv\n",
      "Processing D20240402T121929_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T121929_IFCB124_adc_only.csv\n",
      "Processing D20240402T124330_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T124330_IFCB124_adc_only.csv\n",
      "Processing D20240402T130730_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T130730_IFCB124_adc_only.csv\n",
      "Processing D20240402T133131_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T133131_IFCB124_adc_only.csv\n",
      "Processing D20240402T135532_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T135532_IFCB124_adc_only.csv\n",
      "Processing D20240402T141952_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T141952_IFCB124_adc_only.csv\n",
      "Processing D20240402T144353_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T144353_IFCB124_adc_only.csv\n",
      "Processing D20240402T150753_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T150753_IFCB124_adc_only.csv\n",
      "Processing D20240402T153155_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T153155_IFCB124_adc_only.csv\n",
      "Processing D20240402T155556_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T155556_IFCB124_adc_only.csv\n",
      "Processing D20240402T161956_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T161956_IFCB124_adc_only.csv\n",
      "Processing D20240402T164357_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T164357_IFCB124_adc_only.csv\n",
      "Processing D20240402T170758_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T170758_IFCB124_adc_only.csv\n",
      "Processing D20240402T173158_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T173158_IFCB124_adc_only.csv\n",
      "Processing D20240402T175559_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T175559_IFCB124_adc_only.csv\n",
      "Processing D20240402T182050_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T182050_IFCB124_adc_only.csv\n",
      "Processing D20240402T184451_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T184451_IFCB124_adc_only.csv\n",
      "Processing D20240402T190851_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T190851_IFCB124_adc_only.csv\n",
      "Processing D20240402T193252_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T193252_IFCB124_adc_only.csv\n",
      "Processing D20240402T195652_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T195652_IFCB124_adc_only.csv\n",
      "Processing D20240402T204252_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T204252_IFCB124_adc_only.csv\n",
      "Processing D20240402T210651_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T210651_IFCB124_adc_only.csv\n",
      "Processing D20240402T213052_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T213052_IFCB124_adc_only.csv\n",
      "Processing D20240402T215453_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T215453_IFCB124_adc_only.csv\n",
      "Processing D20240402T221910_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T221910_IFCB124_adc_only.csv\n",
      "Processing D20240402T224311_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/DenseAlex/nauset/zeroRoiMerge/D20240402T224311_IFCB124_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                    use_class_files=False\n",
    "                                    #class_suffixes=\"_class_scores.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERSION 3 \n",
    "## Includes zero roi logic and flexible class inputs\n",
    "### allows for zero roi maintained and give null values for class scores also included bolian isZeroRoi with 1 = yes is zero roi and 0 = not zero roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def ingest_ifcb(\n",
    "    adc_path: str,\n",
    "    hdr_path: str,\n",
    "    class_csv_path: Optional[str] = None,\n",
    "    drop_zero_roi: bool = True,\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Ingest IFCB ADC+HDR, optionally merge with a class CSV (if provided and exists).\n",
    "\n",
    "    Updates:\n",
    "      - Adds IsZeroRoi (1 if RoiX=RoiY=RoiHeight=RoiWidth=0 else 0)\n",
    "      - Drops early false trigger(s) BEFORE drop_zero_roi\n",
    "      - Recomputes InhibitTimeDiff after filtering:\n",
    "            first row: InhibitTimeDiff = InhibitTime\n",
    "            later rows: InhibitTimeDiff = diff(InhibitTime)\n",
    "      - If class file exists: merges ADC->class (left join on RoiNumber) so zero ROIs are preserved\n",
    "        and fills missing class values with 0.\n",
    "\n",
    "    Returns:\n",
    "        out_df: merged (adc + class if available) OR adc-only table\n",
    "        adc_df: full ADC dataframe with derived columns\n",
    "        class_df: loaded class dataframe if available else None\n",
    "    \"\"\"\n",
    "    adc_path = Path(adc_path)\n",
    "    hdr_path = Path(hdr_path)\n",
    "    class_path = Path(class_csv_path) if class_csv_path else None\n",
    "\n",
    "    # 1) Parse ADCFileFormat from .hdr\n",
    "    headers = None\n",
    "    with open(hdr_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ADCFileFormat:\"):\n",
    "                headers = [h.strip() for h in line.split(\":\", 1)[1].split(\",\")]\n",
    "                break\n",
    "    if not headers:\n",
    "        raise ValueError(f\"ADCFileFormat not found in header file: {hdr_path}\")\n",
    "\n",
    "    # 2) Load .adc with headers\n",
    "    adc_df = pd.read_csv(adc_path, header=None)\n",
    "    adc_df.columns = headers[:adc_df.shape[1]]\n",
    "\n",
    "    # 3) Add RoiNumber to ADC as 1..N (do NOT change after this)\n",
    "    adc_df[\"RoiNumber\"] = range(1, len(adc_df) + 1)\n",
    "\n",
    "    # --- NEW: IsZeroRoi flag (computed before any dropping) ---\n",
    "    roi_cols = ['RoiX', 'RoiY', 'RoiHeight', 'RoiWidth']\n",
    "    if all(c in adc_df.columns for c in roi_cols):\n",
    "        for c in roi_cols:\n",
    "            adc_df[c] = pd.to_numeric(adc_df[c], errors='coerce')\n",
    "        adc_df[\"IsZeroRoi\"] = (\n",
    "            (adc_df[\"RoiX\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiY\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiHeight\"].fillna(0) == 0) &\n",
    "            (adc_df[\"RoiWidth\"].fillna(0) == 0)\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        adc_df[\"IsZeroRoi\"] = 0\n",
    "\n",
    "    # ---- drop early false trigger(s) BEFORE drop_zero_roi ----\n",
    "    if drop_false_trigger:\n",
    "        needed = set(roi_cols + ['RunTime'])\n",
    "        if needed.issubset(adc_df.columns) and len(adc_df) > 0:\n",
    "            adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "\n",
    "            false_mask = (\n",
    "                (adc_df['RunTime'] < false_trigger_runtime_s) &\n",
    "                (adc_df[\"IsZeroRoi\"] == 1)\n",
    "            )\n",
    "\n",
    "            if false_mask.any():\n",
    "                adc_df = adc_df.loc[~false_mask]  # preserve RoiNumber; don't reset index\n",
    "\n",
    "    # 4) Remove zero-ROI rows (preserving original RoiNumber values)\n",
    "    if drop_zero_roi and \"IsZeroRoi\" in adc_df.columns:\n",
    "        adc_df = adc_df.loc[adc_df[\"IsZeroRoi\"] == 0]  # keep original RoiNumber; don't reset index\n",
    "\n",
    "    # 5) InhibitTimeDiff (with special first-row rule after filtering)\n",
    "    if 'InhibitTime' in adc_df.columns:\n",
    "        adc_df['InhibitTime'] = pd.to_numeric(adc_df['InhibitTime'], errors='coerce')\n",
    "\n",
    "        adc_df['InhibitTimeDiff'] = adc_df['InhibitTime'].diff()\n",
    "\n",
    "        # first remaining row: InhibitTimeDiff = InhibitTime\n",
    "        if len(adc_df) > 0:\n",
    "            first_idx = adc_df.index[0]\n",
    "            adc_df.loc[first_idx, 'InhibitTimeDiff'] = adc_df.loc[first_idx, 'InhibitTime']\n",
    "\n",
    "        # safety: fill NaNs and clamp negatives\n",
    "        adc_df['InhibitTimeDiff'] = pd.to_numeric(adc_df['InhibitTimeDiff'], errors='coerce').fillna(0.0)\n",
    "        adc_df.loc[adc_df['InhibitTimeDiff'] < 0, 'InhibitTimeDiff'] = 0.0\n",
    "    else:\n",
    "        adc_df['InhibitTimeDiff'] = pd.NA\n",
    "\n",
    "    # 6) VolumeAnalyzed\n",
    "    if {'RunTime', 'InhibitTime'}.issubset(adc_df.columns):\n",
    "        adc_df['RunTime'] = pd.to_numeric(adc_df['RunTime'], errors='coerce')\n",
    "        adc_df['VolumeAnalyzed'] = (adc_df['RunTime'] - adc_df['InhibitTime']) / 240\n",
    "    else:\n",
    "        adc_df['VolumeAnalyzed'] = pd.NA\n",
    "\n",
    "    # Columns to expose from ADC side\n",
    "    cols_to_keep = ['RoiNumber', 'ADCtime', 'RunTime', 'InhibitTime', 'InhibitTimeDiff', 'VolumeAnalyzed', 'IsZeroRoi']\n",
    "    for extra in ['RoiHeight', 'RoiWidth', 'RoiX', 'RoiY']:\n",
    "        if extra in adc_df.columns:\n",
    "            cols_to_keep.append(extra)\n",
    "\n",
    "    adc_out = adc_df[cols_to_keep].copy()\n",
    "\n",
    "    # 7-8) Optional: Load class CSV + merge (ADC-driven to preserve zero ROIs)\n",
    "    class_df = None\n",
    "    if class_path and class_path.exists():\n",
    "        class_df = pd.read_csv(class_path)\n",
    "\n",
    "        if 'pid' not in class_df.columns:\n",
    "            raise ValueError(f\"Expected 'pid' column in class CSV to extract RoiNumber: {class_path}\")\n",
    "\n",
    "        class_df['RoiNumber'] = class_df['pid'].str.split('_').str[-1].astype(int)\n",
    "\n",
    "        # ADC -> class (left) keeps all ADC rows, including zero ROIs\n",
    "        merged_df = adc_out.merge(class_df, on='RoiNumber', how='left')\n",
    "\n",
    "        # Fill missing class values with 0 (e.g., zero ROIs)\n",
    "        class_cols = [c for c in class_df.columns if c not in ['pid', 'RoiNumber']]\n",
    "        if class_cols:\n",
    "            merged_df[class_cols] = merged_df[class_cols].fillna(0)\n",
    "\n",
    "        return merged_df, adc_df, class_df\n",
    "\n",
    "    # No class file: return ADC-derived table as the \"merged\" output\n",
    "    return adc_out, adc_df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Sequence\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_ifcb_directory(\n",
    "    directory: str,\n",
    "    drop_zero_roi: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    class_suffixes: Optional[Sequence[str]] = (\"_class_vNone.csv\", \"_class.csv\"),\n",
    "    adc_only_suffix: str = \"_adc_only.csv\",\n",
    "    prefer_newest_class_file: bool = True,\n",
    "    drop_false_trigger: bool = True,\n",
    "    false_trigger_runtime_s: float = 0.25,\n",
    "    use_class_files: bool = True,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    directory = Path(directory)\n",
    "    save_dir = Path(save_path) if save_path else directory\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    adc_map = {p.stem: p for p in directory.glob(\"*.adc\")}\n",
    "    hdr_map = {p.stem: p for p in directory.glob(\"*.hdr\")}\n",
    "\n",
    "    prefixes = sorted(set(adc_map).intersection(set(hdr_map)))\n",
    "\n",
    "    class_candidates = sorted([p for p in directory.glob(\"*.csv\") if \"class\" in p.name.lower()])\n",
    "\n",
    "    def _matches_any_pattern(filename: str, prefix: str) -> bool:\n",
    "        if not class_suffixes:\n",
    "            return True\n",
    "\n",
    "        for tok in class_suffixes:\n",
    "            tok = str(tok)\n",
    "            has_wild = any(ch in tok for ch in [\"*\", \"?\", \"[\"])\n",
    "            if has_wild:\n",
    "                if fnmatch.fnmatch(filename, f\"{prefix}{tok}\") or fnmatch.fnmatch(filename, tok):\n",
    "                    return True\n",
    "            else:\n",
    "                if filename.startswith(prefix) and filename.endswith(tok):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    class_map: Dict[str, Path] = {}\n",
    "    for prefix in prefixes:\n",
    "        matches = []\n",
    "        for p in class_candidates:\n",
    "            if not p.name.startswith(prefix):\n",
    "                continue\n",
    "            if _matches_any_pattern(p.name, prefix):\n",
    "                matches.append(p)\n",
    "\n",
    "        if matches:\n",
    "            if prefer_newest_class_file:\n",
    "                best = max(matches, key=lambda x: x.stat().st_mtime)\n",
    "            else:\n",
    "                best = sorted(matches, key=lambda x: x.name)[0]\n",
    "            class_map[prefix] = best\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        adc_path = adc_map[prefix]\n",
    "        hdr_path = hdr_map[prefix]\n",
    "        class_path = class_map.get(prefix) if use_class_files else None\n",
    "\n",
    "        print(f\"Processing {prefix} (class={'yes' if class_path else 'no'})...\")\n",
    "\n",
    "        out_df, adc_df, class_df = ingest_ifcb(\n",
    "            adc_path=str(adc_path),\n",
    "            hdr_path=str(hdr_path),\n",
    "            class_csv_path=str(class_path) if class_path else None,\n",
    "            drop_zero_roi=drop_zero_roi,\n",
    "            drop_false_trigger=drop_false_trigger,\n",
    "            false_trigger_runtime_s=false_trigger_runtime_s,\n",
    "        )\n",
    "\n",
    "        results[prefix] = out_df\n",
    "\n",
    "        # ---- minimal (optional) naming clarity ----\n",
    "        if class_df is not None:\n",
    "            if drop_zero_roi:\n",
    "                outfile = save_dir / f\"{prefix}_merged.csv\"\n",
    "            else:\n",
    "                outfile = save_dir / f\"{prefix}_merged_keepzero.csv\"\n",
    "        else:\n",
    "            outfile = save_dir / f\"{prefix}{adc_only_suffix}\"\n",
    "\n",
    "        out_df.to_csv(outfile, index=False)\n",
    "        print(f\"Saved: {outfile}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/\"\n",
    "merged_dir = \"../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D20260124T011016_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T011016_IFCB124_adc_only.csv\n",
      "Processing D20260124T014235_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T014235_IFCB149_adc_only.csv\n",
      "Processing D20260124T015641_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T015641_IFCB124_adc_only.csv\n",
      "Processing D20260124T022904_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T022904_IFCB149_adc_only.csv\n",
      "Processing D20260124T024306_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T024306_IFCB124_adc_only.csv\n",
      "Processing D20260124T031533_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T031533_IFCB149_adc_only.csv\n",
      "Processing D20260124T032932_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T032932_IFCB124_adc_only.csv\n",
      "Processing D20260124T040202_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T040202_IFCB149_adc_only.csv\n",
      "Processing D20260124T041557_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T041557_IFCB124_adc_only.csv\n",
      "Processing D20260124T044831_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T044831_IFCB149_adc_only.csv\n",
      "Processing D20260124T050222_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T050222_IFCB124_adc_only.csv\n",
      "Processing D20260124T053500_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T053500_IFCB149_adc_only.csv\n",
      "Processing D20260124T054848_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T054848_IFCB124_adc_only.csv\n",
      "Processing D20260124T062129_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T062129_IFCB149_adc_only.csv\n",
      "Processing D20260124T063513_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T063513_IFCB124_adc_only.csv\n",
      "Processing D20260124T070758_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T070758_IFCB149_adc_only.csv\n",
      "Processing D20260124T072138_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T072138_IFCB124_adc_only.csv\n",
      "Processing D20260124T075427_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T075427_IFCB149_adc_only.csv\n",
      "Processing D20260124T080806_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T080806_IFCB124_adc_only.csv\n",
      "Processing D20260124T084056_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T084056_IFCB149_adc_only.csv\n",
      "Processing D20260124T085432_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T085432_IFCB124_adc_only.csv\n",
      "Processing D20260124T092725_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T092725_IFCB149_adc_only.csv\n",
      "Processing D20260124T094057_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T094057_IFCB124_adc_only.csv\n",
      "Processing D20260124T101354_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T101354_IFCB149_adc_only.csv\n",
      "Processing D20260124T102723_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T102723_IFCB124_adc_only.csv\n",
      "Processing D20260124T110023_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T110023_IFCB149_adc_only.csv\n",
      "Processing D20260124T111347_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T111347_IFCB124_adc_only.csv\n",
      "Processing D20260124T114652_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T114652_IFCB149_adc_only.csv\n",
      "Processing D20260124T120012_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T120012_IFCB124_adc_only.csv\n",
      "Processing D20260124T123320_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T123320_IFCB149_adc_only.csv\n",
      "Processing D20260124T124637_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T124637_IFCB124_adc_only.csv\n",
      "Processing D20260124T131949_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T131949_IFCB149_adc_only.csv\n",
      "Processing D20260124T133303_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T133303_IFCB124_adc_only.csv\n",
      "Processing D20260124T140618_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T140618_IFCB149_adc_only.csv\n",
      "Processing D20260124T141928_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T141928_IFCB124_adc_only.csv\n",
      "Processing D20260124T145247_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T145247_IFCB149_adc_only.csv\n",
      "Processing D20260124T150554_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T150554_IFCB124_adc_only.csv\n",
      "Processing D20260124T153916_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T153916_IFCB149_adc_only.csv\n",
      "Processing D20260124T155219_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T155219_IFCB124_adc_only.csv\n",
      "Processing D20260124T162545_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T162545_IFCB149_adc_only.csv\n",
      "Processing D20260124T163844_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T163844_IFCB124_adc_only.csv\n",
      "Processing D20260124T171214_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T171214_IFCB149_adc_only.csv\n",
      "Processing D20260124T172510_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T172510_IFCB124_adc_only.csv\n",
      "Processing D20260124T175843_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T175843_IFCB149_adc_only.csv\n",
      "Processing D20260124T181136_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T181136_IFCB124_adc_only.csv\n",
      "Processing D20260124T184511_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T184511_IFCB149_adc_only.csv\n",
      "Processing D20260124T185801_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T185801_IFCB124_adc_only.csv\n",
      "Processing D20260124T193139_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T193139_IFCB149_adc_only.csv\n",
      "Processing D20260124T194427_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T194427_IFCB124_adc_only.csv\n",
      "Processing D20260124T203052_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T203052_IFCB124_adc_only.csv\n",
      "Processing D20260124T210437_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T210437_IFCB149_adc_only.csv\n",
      "Processing D20260124T211717_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T211717_IFCB124_adc_only.csv\n",
      "Processing D20260124T215106_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T215106_IFCB149_adc_only.csv\n",
      "Processing D20260124T220343_IFCB124 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T220343_IFCB124_adc_only.csv\n",
      "Processing D20260124T223735_IFCB149 (class=no)...\n",
      "Saved: ../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T223735_IFCB149_adc_only.csv\n"
     ]
    }
   ],
   "source": [
    "merged_dict = ingest_ifcb_directory(directory= test_dir,\n",
    "                                   save_path= merged_dir,\n",
    "                                   drop_zero_roi=False,\n",
    "                                   drop_false_trigger=True,\n",
    "                                   false_trigger_runtime_s=0.25,\n",
    "                                    use_class_files=False,\n",
    "                                    class_suffixes=\"_class_scores.csv\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test if it worked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"../../IFCBData/dilExp/jataLowV/hablab_jata_lowV/merged/D20260124T211717_IFCB124_adc_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count is 9137 total volume analyzed is 4.1948725405092615 rois/ml: 2178.135309658481\n"
     ]
    }
   ],
   "source": [
    "count_zeroroi = (testdf['IsZeroRoi'] == 0).sum()\n",
    "v_analyzed = (testdf['VolumeAnalyzed'].max())\n",
    "roi_per_ml = count_zeroroi/(v_analyzed)\n",
    "print('total count is', count_zeroroi, 'total volume analyzed is', v_analyzed, 'rois/ml:', roi_per_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoiNumber</th>\n",
       "      <th>ADCtime</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>InhibitTime</th>\n",
       "      <th>InhibitTimeDiff</th>\n",
       "      <th>VolumeAnalyzed</th>\n",
       "      <th>IsZeroRoi</th>\n",
       "      <th>RoiHeight</th>\n",
       "      <th>RoiWidth</th>\n",
       "      <th>RoiX</th>\n",
       "      <th>RoiY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>11.815466</td>\n",
       "      <td>11.837999</td>\n",
       "      <td>1.018529</td>\n",
       "      <td>0.084347</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>315</td>\n",
       "      <td>47.918396</td>\n",
       "      <td>47.941936</td>\n",
       "      <td>26.710356</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>445</td>\n",
       "      <td>62.915347</td>\n",
       "      <td>62.937500</td>\n",
       "      <td>37.646628</td>\n",
       "      <td>0.083772</td>\n",
       "      <td>0.105379</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>643</td>\n",
       "      <td>85.405384</td>\n",
       "      <td>85.428264</td>\n",
       "      <td>54.382031</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1203</td>\n",
       "      <td>152.617584</td>\n",
       "      <td>152.642639</td>\n",
       "      <td>102.356745</td>\n",
       "      <td>0.084323</td>\n",
       "      <td>0.209525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1257</td>\n",
       "      <td>159.111661</td>\n",
       "      <td>159.135139</td>\n",
       "      <td>106.943160</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>0.217467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1329</td>\n",
       "      <td>167.766248</td>\n",
       "      <td>167.791215</td>\n",
       "      <td>113.182769</td>\n",
       "      <td>0.085660</td>\n",
       "      <td>0.227535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>1431</td>\n",
       "      <td>180.102610</td>\n",
       "      <td>180.129583</td>\n",
       "      <td>121.875017</td>\n",
       "      <td>0.088281</td>\n",
       "      <td>0.242727</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1581</td>\n",
       "      <td>197.412408</td>\n",
       "      <td>197.437431</td>\n",
       "      <td>134.494366</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.262263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1814</td>\n",
       "      <td>224.102733</td>\n",
       "      <td>224.124097</td>\n",
       "      <td>154.028576</td>\n",
       "      <td>0.080330</td>\n",
       "      <td>0.292065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RoiNumber     ADCtime     RunTime  InhibitTime  InhibitTimeDiff  \\\n",
       "11           13   11.815466   11.837999     1.018529         0.084347   \n",
       "313         315   47.918396   47.941936    26.710356         0.085714   \n",
       "443         445   62.915347   62.937500    37.646628         0.083772   \n",
       "641         643   85.405384   85.428264    54.382031         0.083385   \n",
       "1201       1203  152.617584  152.642639   102.356745         0.084323   \n",
       "1255       1257  159.111661  159.135139   106.943160         0.085026   \n",
       "1327       1329  167.766248  167.791215   113.182769         0.085660   \n",
       "1429       1431  180.102610  180.129583   121.875017         0.088281   \n",
       "1579       1581  197.412408  197.437431   134.494366         0.085000   \n",
       "1812       1814  224.102733  224.124097   154.028576         0.080330   \n",
       "\n",
       "      VolumeAnalyzed  IsZeroRoi  RoiHeight  RoiWidth  RoiX  RoiY  \n",
       "11          0.045081          1          0         0     0     0  \n",
       "313         0.088465          1          0         0     0     0  \n",
       "443         0.105379          1          0         0     0     0  \n",
       "641         0.129359          1          0         0     0     0  \n",
       "1201        0.209525          1          0         0     0     0  \n",
       "1255        0.217467          1          0         0     0     0  \n",
       "1327        0.227535          1          0         0     0     0  \n",
       "1429        0.242727          1          0         0     0     0  \n",
       "1579        0.262263          1          0         0     0     0  \n",
       "1812        0.292065          1          0         0     0     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.loc[testdf[\"IsZeroRoi\"] == 1].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(testdf['VolumeAnalyzed'],testdf['RoiNumber'])\n",
    "plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
